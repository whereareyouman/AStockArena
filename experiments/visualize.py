#!/usr/bin/env python3
"""
PnL Visualization Script for AStock Arena
Generates three comparison charts: intraday, daily, and weekly PnL across all models.
"""

import json
from pathlib import Path
from datetime import datetime
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple
import numpy as np
from scipy.interpolate import make_interp_spline
import pandas as pd
import os

# åŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    from dotenv import load_dotenv
    # å°è¯•ä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½ .env æ–‡ä»¶
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ“ Loaded .env file from {env_path}")
    else:
        # å¦‚æœé¡¹ç›®æ ¹ç›®å½•æ²¡æœ‰ï¼Œå°è¯•ä»å½“å‰ç›®å½•åŠ è½½
        load_dotenv()
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£… python-dotenvï¼Œè·³è¿‡
    pass
except Exception as e:
    print(f"âš ï¸ Warning: Failed to load .env file: {e}")


plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


ROOT_DIR = Path(__file__).parent
PROJECT_ROOT = ROOT_DIR.parent
OUTPUT_DIR = ROOT_DIR / "visualizations"
OUTPUT_DIR.mkdir(exist_ok=True)

# Date range filter (inclusive)
DATE_FILTER_START = datetime.strptime("2026-01-12 00:00:00", "%Y-%m-%d %H:%M:%S")
DATE_FILTER_END = datetime.strptime("2026-01-23 23:59:59", "%Y-%m-%d %H:%M:%S")


def in_date_range(dt: datetime) -> bool:
    """Return True if dt is within configured date window (inclusive)."""
    return DATE_FILTER_START <= dt <= DATE_FILTER_END

# PnL snapshots directory
PNL_SNAPSHOTS_DIR = PROJECT_ROOT / "data_flow" / "pnl_snapshots"

# Legacy data directories (for backward compatibility)
DATA_DATES = [f"data_{day}_1_2026" for day in range(12, 17)]

# 10åªè‚¡ç¥¨ï¼ˆç­‰æƒé‡ETFç»„æˆï¼‰
ETF_STOCKS = [
    "SH688008",  # æ¾œèµ·ç§‘æŠ€
    "SH688111",  # é‡‘å±±åŠå…¬
    "SH688009",  # ä¸­å›½é€šå·
    "SH688981",  # ä¸­èŠ¯å›½é™…
    "SH688256",  # å¯’æ­¦çºª
    "SH688271",  # è”å½±åŒ»ç–—
    "SH688047",  # é¾™èŠ¯ä¸­ç§‘
    "SH688617",  # æƒ æ³°åŒ»ç–—
    "SH688303",  # å¤§å…¨èƒ½æº
    "SH688180",  # å›å®ç”Ÿç‰©
]


# ä½é…ç‰ˆæ¨¡å‹ï¼ˆLiteç‰ˆæœ¬ï¼‰
MODELS_LITE = {
    "claude-haiku-4-5": {
        "color": "#8B5CF6", 
        "label": "Claude Haiku 4.5"
    },
    "deepseek-chat": {
        "color": "#F59E0B", 
        "label": "DeepSeek Chat"
    },
    "gpt-5.1": {
        "color": "#3B82F6", 
        "label": "GPT-5.1"
    },
    "qwen3-235b": {
        "color": "#EF4444", 
        "label": "Qwen3-235b"
    },
    "gemini-2.5-flash": {
        "color": "#10B981", 
        "label": "Gemini 2.5 Flash"
    }
}

# å‡çº§ç‰ˆæ¨¡å‹ï¼ˆProç‰ˆæœ¬ï¼‰
MODELS_PRO = {
    "claude-opus-4-5": {
        "color": "#8B5CF6", 
        "label": "Claude Opus 4.5"
    },
    "deepseek-reasoner": {
        "color": "#F59E0B", 
        "label": "DeepSeek Reasoner"
    },
    "gpt-5.2": {
        "color": "#3B82F6", 
        "label": "GPT-5.2"
    },
    "qwen3-max": {
        "color": "#EF4444", 
        "label": "Qwen3-Max"
    },
    "gemini-3-pro-preview": {
        "color": "#10B981", 
        "label": "Gemini 3 Pro Preview"
    }
}

# æ¨¡å‹ç‰ˆæœ¬å¯¹æ¯”æ˜ å°„
MODEL_PAIRS = {
    "claude-haiku-4-5": "claude-opus-4-5",
    "deepseek-chat": "deepseek-reasoner",
    "gpt-5.1": "gpt-5.2",
    "qwen3-235b": "qwen3-max",
    "gemini-2.5-flash": "gemini-3-pro-preview"
}

# é»˜è®¤é€‰æ‹© Lite ç‰ˆæœ¬ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡æˆ–å‚æ•°ä¿®æ”¹
import os
MODEL_VERSION = os.getenv("MODEL_VERSION", "lite").lower()
MODELS = MODELS_LITE if MODEL_VERSION == "lite" else MODELS_PRO

print(f"ğŸ“Œ Using {MODEL_VERSION.upper()} models: {list(MODELS.keys())}")

INITIAL_CAPITAL = 1000000.0


def read_position_data(model_signature: str, data_dir: str = None) -> List[Dict]:
    """è¯»å–æ¨¡å‹çš„æŒä»“æ•°æ®"""
    # ä¼˜å…ˆä½¿ç”¨æ–°çš„ç›®å½•ç»“æ„
    position_file = PROJECT_ROOT / "data_flow" / "trading_summary_each_agent" / model_signature / "position" / "position.jsonl"
    
    # å¦‚æœæ–°è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•æ—§è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰
    if not position_file.exists() and data_dir:
        position_file = ROOT_DIR / data_dir / "agent_data" / model_signature / "position" / "position.jsonl"
    
    if not position_file.exists():
        return []
    
    positions = []
    with open(position_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                positions.append(json.loads(line))
    
    return positions


def get_price_at_time(symbol: str, decision_time: str, date_str: str = None) -> float:
    """æ ¹æ®å†³ç­–æ—¶ç‚¹è·å–è‚¡ç¥¨å¸‚åœºä»·æ ¼ï¼ˆä» ai_stock_data.jsonï¼‰"""
    stock_data_path = PROJECT_ROOT / "data_flow" / "ai_stock_data.json"
    if not stock_data_path.exists():
        return 0.0
    
    try:
        with open(stock_data_path, 'r', encoding='utf-8') as f:
            full_data = json.load(f)
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„é”®å
        stock_entry = None
        symbol_upper = symbol.upper()
        for key in [symbol_upper, symbol_upper.replace("SH", "").replace("SZ", ""), f"SH{symbol_upper}", f"SZ{symbol_upper}"]:
            if key in full_data:
                stock_entry = full_data[key]
                break
        
        if not stock_entry or not isinstance(stock_entry, dict):
            return 0.0
        
        # ä¼˜å…ˆä½¿ç”¨å°æ—¶çº¿è¡Œæƒ…ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ—¥çº¿è¡Œæƒ…
        hourly_data = stock_entry.get("å°æ—¶çº¿è¡Œæƒ…") or []
        daily_data = stock_entry.get("æ—¥çº¿è¡Œæƒ…") or []
        
        data_list = hourly_data if hourly_data else daily_data
        if not data_list:
            return 0.0
        
        # æ ¹æ® decision_time æŸ¥æ‰¾ <= ç›®æ ‡æ—¶é—´çš„æœ€æ–°ä»·æ ¼
        target_time = decision_time or (date_str + " 15:00:00" if date_str else None)
        if not target_time:
            last_item = data_list[-1]
            return float(last_item.get("close") or last_item.get("buy1") or 0)
        
        # å€’åºéå†ï¼Œæ‰¾ç¬¬ä¸€ä¸ª <= target_time çš„è®°å½•
        best_match = None
        for item in reversed(data_list):
            item_time = item.get("time") or item.get("date") or ""
            if item_time and item_time <= target_time:
                best_match = item
                break
        
        if best_match:
            return float(best_match.get("close") or best_match.get("buy1") or 0)
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›ç¬¬ä¸€æ¡è®°å½•çš„ä»·æ ¼ï¼ˆæœ€æ—©çš„ä»·æ ¼ï¼‰
        first_item = data_list[0]
        return float(first_item.get("close") or first_item.get("buy1") or 0)
        
    except Exception:
        return 0.0


def calculate_equity_with_cost_price(position_data: Dict) -> float:
    """è®¡ç®—è´¦æˆ·æƒç›Šï¼ˆä½¿ç”¨æˆæœ¬ä»·ï¼‰= ç°é‡‘ + æŒä»“æˆæœ¬ï¼ˆavg_price * sharesï¼‰"""
    cash = float(position_data.get('positions', {}).get('CASH', 0))
    equity = cash
    
    positions = position_data.get('positions', {})
    for symbol, info in positions.items():
        if symbol != 'CASH' and isinstance(info, dict):
            shares = float(info.get('shares', 0))
            avg_price = float(info.get('avg_price', 0))
            if shares > 0 and avg_price > 0:
                # ä½¿ç”¨æˆæœ¬ä»·è®¡ç®—
                equity += shares * avg_price
    
    return equity


def calculate_equity_with_market_price(position_data: Dict, decision_time: str, date_str: str = None) -> float:
    """è®¡ç®—è´¦æˆ·æƒç›Šï¼ˆä½¿ç”¨å¸‚åœºä»·æ ¼ï¼‰= ç°é‡‘ + æŒä»“å¸‚å€¼ï¼ˆå†³ç­–æ—¶ç‚¹çš„å¸‚åœºä»·æ ¼ï¼‰"""
    cash = float(position_data.get('positions', {}).get('CASH', 0))
    equity = cash
    
    positions = position_data.get('positions', {})
    for symbol, info in positions.items():
        if symbol != 'CASH' and isinstance(info, dict):
            shares = float(info.get('shares', 0))
            if shares > 0:
                # ä½¿ç”¨å†³ç­–æ—¶ç‚¹çš„å¸‚åœºä»·æ ¼
                current_price = get_price_at_time(symbol, decision_time, date_str)
                equity += shares * current_price
    
    return equity


def read_pnl_snapshot(model_signature: str) -> List[Dict]:
    """è¯»å–æ¨¡å‹çš„ PnL å¿«ç…§æ–‡ä»¶"""
    # æ–‡ä»¶åæ ¼å¼: pnl_{signature}.json
    pnl_file = PNL_SNAPSHOTS_DIR / f"pnl_{model_signature}.json"
    
    if not pnl_file.exists():
        return []
    
    try:
        with open(pnl_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš  Warning: Failed to read PnL snapshot for {model_signature}: {e}")
        return []


def extract_unrealized_pnl() -> Dict[str, List[Tuple[datetime, float, float]]]:
    """
    æå– Unrealized PnLï¼ˆæµ®åŠ¨ç›ˆäºï¼‰
    ä» position.jsonl è®¡ç®—ï¼Œä½¿ç”¨å¸‚åœºä»·æ ¼ï¼ˆdecision_time çš„ä»·æ ¼ï¼‰
    è¿”å›: {model_signature: [(datetime, equity, return_pct), ...]}
    
    Unrealized PnL = ç°é‡‘ + æŒä»“å¸‚å€¼ï¼ˆshares * å½“å‰å¸‚åœºä»·æ ¼ï¼‰
    è¿™æ˜¯æµ®åŠ¨æƒç›Šï¼Œä¼šéšå¸‚åœºä»·æ ¼å˜åŒ–è€Œæ³¢åŠ¨ã€‚
    """
    all_pnl_data = {}
    
    for model_sig in MODELS.keys():
        pnl_series = []
        
        # ä» position.jsonl è®¡ç®—ï¼ˆä½¿ç”¨å¸‚åœºä»·æ ¼ï¼‰
        # ä¼˜å…ˆä½¿ç”¨æ–°ç›®å½•ç»“æ„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•æ—§ç›®å½•ç»“æ„
        positions = read_position_data(model_sig)
        
        # å¦‚æœæ–°ç›®å½•æ²¡æœ‰æ•°æ®ï¼Œå°è¯•æ—§ç›®å½•ç»“æ„ï¼ˆå‘åå…¼å®¹ï¼‰
        if not positions:
            for data_dir in DATA_DATES:
                positions = read_position_data(model_sig, data_dir)
                if positions:
                    break
        
        for pos in positions:
            # è·³è¿‡seedè®°å½•
            if pos.get('seed', False):
                continue
            
            decision_time_str = pos.get('decision_time', '')
            date_str = pos.get('date', '')
            if not decision_time_str:
                continue
            
            try:
                dt = datetime.strptime(decision_time_str, "%Y-%m-%d %H:%M:%S")
            except ValueError:
                continue

            if not in_date_range(dt):
                continue
            
            # ä½¿ç”¨å¸‚åœºä»·æ ¼ï¼ˆå†³ç­–æ—¶ç‚¹çš„ä»·æ ¼ï¼‰è®¡ç®—æƒç›Š
            equity = calculate_equity_with_market_price(pos, decision_time_str, date_str)
            return_pct = ((equity - INITIAL_CAPITAL) / INITIAL_CAPITAL) * 100
            
            pnl_series.append((dt, equity, return_pct))
        
        if pnl_series:
            all_pnl_data[model_sig] = sorted(pnl_series, key=lambda x: x[0])
            print(f"âœ“ Loaded {len(pnl_series)} unrealized PnL points for {model_sig} (using market price)")
    
    return all_pnl_data


def extract_unrealized_pnl_by_models(model_dict: Dict) -> Dict[str, List[Tuple[datetime, float, float]]]:
    """
    æå–æŒ‡å®šæ¨¡å‹å­—å…¸ä¸­çš„ Unrealized PnLï¼ˆæµ®åŠ¨ç›ˆäºï¼‰
    ä» position.jsonl è®¡ç®—ï¼Œä½¿ç”¨å¸‚åœºä»·æ ¼ï¼ˆdecision_time çš„ä»·æ ¼ï¼‰
    è¿”å›: {model_signature: [(datetime, equity, return_pct), ...]}
    """
    all_pnl_data = {}
    
    for model_sig in model_dict.keys():
        pnl_series = []
        
        # ä» position.jsonl è®¡ç®—ï¼ˆä½¿ç”¨å¸‚åœºä»·æ ¼ï¼‰
        positions = read_position_data(model_sig)
        
        # å¦‚æœæ–°ç›®å½•æ²¡æœ‰æ•°æ®ï¼Œå°è¯•æ—§ç›®å½•ç»“æ„ï¼ˆå‘åå…¼å®¹ï¼‰
        if not positions:
            for data_dir in DATA_DATES:
                positions = read_position_data(model_sig, data_dir)
                if positions:
                    break
        
        for pos in positions:
            if pos.get('seed', False):
                continue
            
            decision_time_str = pos.get('decision_time', '')
            date_str = pos.get('date', '')
            if not decision_time_str:
                continue
            
            try:
                dt = datetime.strptime(decision_time_str, "%Y-%m-%d %H:%M:%S")
            except ValueError:
                continue

            if not in_date_range(dt):
                continue
            
            equity = calculate_equity_with_market_price(pos, decision_time_str, date_str)
            return_pct = ((equity - INITIAL_CAPITAL) / INITIAL_CAPITAL) * 100
            pnl_series.append((dt, equity, return_pct))
        
        if pnl_series:
            all_pnl_data[model_sig] = sorted(pnl_series, key=lambda x: x[0])
    
    return all_pnl_data


def extract_realized_pnl_by_models(model_dict: Dict) -> Dict[str, List[Tuple[datetime, float, float]]]:
    """
    æå–æŒ‡å®šæ¨¡å‹å­—å…¸ä¸­çš„ Realized PnLï¼ˆåŸºäºæˆæœ¬ä»·çš„æƒç›Šï¼‰
    ä» position.jsonl è®¡ç®—ï¼Œä½¿ç”¨æˆæœ¬ä»·ï¼ˆavg_priceï¼‰
    è¿”å›: {model_signature: [(datetime, equity, return_pct), ...]}
    """
    all_pnl_data = {}
    
    for model_sig in model_dict.keys():
        pnl_series = []
        
        # ä» position.jsonl è®¡ç®—ï¼ˆä½¿ç”¨æˆæœ¬ä»·ï¼‰
        positions = read_position_data(model_sig)
        
        # å¦‚æœæ–°ç›®å½•æ²¡æœ‰æ•°æ®ï¼Œå°è¯•æ—§ç›®å½•ç»“æ„ï¼ˆå‘åå…¼å®¹ï¼‰
        if not positions:
            for data_dir in DATA_DATES:
                positions = read_position_data(model_sig, data_dir)
                if positions:
                    break
        
        for pos in positions:
            if pos.get('seed', False):
                continue
            
            decision_time_str = pos.get('decision_time', '')
            if not decision_time_str:
                continue
            
            try:
                dt = datetime.strptime(decision_time_str, "%Y-%m-%d %H:%M:%S")
            except ValueError:
                continue

            if not in_date_range(dt):
                continue
            
            equity = calculate_equity_with_cost_price(pos)
            return_pct = ((equity - INITIAL_CAPITAL) / INITIAL_CAPITAL) * 100
            pnl_series.append((dt, equity, return_pct))
        
        if pnl_series:
            all_pnl_data[model_sig] = sorted(pnl_series, key=lambda x: x[0])
    
    return all_pnl_data


def extract_realized_pnl() -> Dict[str, List[Tuple[datetime, float, float]]]:
    """
    æå– Realized PnLï¼ˆåŸºäºæˆæœ¬ä»·çš„æƒç›Šï¼‰
    ä» position.jsonl è®¡ç®—ï¼Œä½¿ç”¨æˆæœ¬ä»·ï¼ˆavg_priceï¼‰
    è¿”å›: {model_signature: [(datetime, equity, return_pct), ...]}
    
    Realized PnL = ç°é‡‘ + æŒä»“æˆæœ¬ï¼ˆshares * avg_priceï¼‰
    è¿™æ˜¯å·²å®ç°çš„æƒç›Šï¼Œä¸ä¼šéšå¸‚åœºä»·æ ¼æµ®åŠ¨ã€‚
    """
    return extract_realized_pnl_by_models(MODELS)


def extract_stock_attention(model_dict: Dict = None) -> Dict[datetime, Dict[str, int]]:
    """
    æå–è‚¡ç¥¨å…³æ³¨åº¦æ•°æ®ï¼ˆæ¯ä¸ªæ—¶é—´ç‚¹ï¼Œæ¯æ”¯è‚¡ç¥¨è¢«å¤šå°‘ä¸ªæ¨¡å‹æŒæœ‰ï¼‰
    è¿”å›: {datetime: {stock_symbol: num_models_holding, ...}, ...}
    å¯é€šè¿‡ model_dict æŒ‡å®šæ¨¡å‹å­é›†ï¼ˆé»˜è®¤å…¨é‡ MODELSï¼‰ã€‚
    """
    if model_dict is None:
        model_dict = MODELS

    # ä½¿ç”¨åµŒå¥—å­—å…¸å­˜å‚¨ï¼š{datetime: {stock_symbol: set(models_holding)}}
    attention_data_sets = {}
    
    for model_sig in model_dict.keys():
        # éå†æ‰€æœ‰æ—¥æœŸç›®å½•
        for data_dir in DATA_DATES:
            positions = read_position_data(model_sig, data_dir)
            
            for pos in positions:
                # è·³è¿‡seedè®°å½•
                if pos.get('seed', False):
                    continue
                
                decision_time_str = pos.get('decision_time', '')
                if not decision_time_str:
                    continue
                
                try:
                    dt = datetime.strptime(decision_time_str, "%Y-%m-%d %H:%M:%S")
                except ValueError:
                    continue
                
                if not in_date_range(dt):
                    continue
                
                # åˆå§‹åŒ–æ—¶é—´ç‚¹çš„æ•°æ®ç»“æ„
                if dt not in attention_data_sets:
                    attention_data_sets[dt] = {}
                
                # æ”¶é›†è¯¥æ¨¡å‹åœ¨æ­¤æ—¶é—´ç‚¹æŒæœ‰çš„è‚¡ç¥¨
                positions_dict = pos.get('positions', {})
                for symbol, info in positions_dict.items():
                    if symbol != 'CASH' and isinstance(info, dict):
                        shares = info.get('shares', 0)
                        if shares > 0:
                            # åˆå§‹åŒ–è‚¡ç¥¨çš„æ¨¡å‹é›†åˆ
                            if symbol not in attention_data_sets[dt]:
                                attention_data_sets[dt][symbol] = set()
                            # å°†æ¨¡å‹æ·»åŠ åˆ°é›†åˆä¸­ï¼ˆè‡ªåŠ¨å»é‡ï¼‰
                            attention_data_sets[dt][symbol].add(model_sig)
    
    # è½¬æ¢ä¸ºæœ€ç»ˆæ ¼å¼ï¼šè®¡æ•°è€Œéé›†åˆ
    attention_data = {}
    for dt, stocks in attention_data_sets.items():
        attention_data[dt] = {symbol: len(models) for symbol, models in stocks.items()}
    
    # æŒ‰æ—¶é—´æ’åº
    sorted_attention = {dt: attention_data[dt] for dt in sorted(attention_data.keys())}
    return sorted_attention


def extract_model_attention_by_date(model_dict: Dict = None) -> Dict[str, Dict[str, int]]:
    """
    æå–æ¯ä¸ªæ¨¡å‹åœ¨æ¯ä¸ªæ—¥æœŸçš„è‚¡ç¥¨æŒæœ‰æ•°ï¼ˆå–æ¯å¤©å„æ—¶é—´ç‚¹çš„å¹³å‡å€¼ï¼‰
    è¿”å›: {model_sig: {date_str: avg_num_stocks_held, ...}, ...}
    å¯é€šè¿‡ model_dict æŒ‡å®šæ¨¡å‹å­é›†ï¼ˆé»˜è®¤å…¨é‡ MODELSï¼‰ã€‚
    """
    if model_dict is None:
        model_dict = MODELS

    model_attention = {}
    
    for model_sig in model_dict.keys():
        model_attention[model_sig] = {}
        
        positions = read_position_data(model_sig)
        if not positions:
            for data_dir in DATA_DATES:
                positions = read_position_data(model_sig, data_dir)
                if positions:
                    break
        
        date_to_stocks_count = {}  # {date_str: [stocks_count_per_time, ...]}
        
        for pos in positions:
            if pos.get('seed', False):
                continue
            
            date_str = pos.get('date', '')
            if not date_str:
                decision_time_str = pos.get('decision_time', '')
                if decision_time_str:
                    try:
                        dt = datetime.strptime(decision_time_str, "%Y-%m-%d %H:%M:%S")
                        date_str = dt.strftime('%Y-%m-%d')
                    except ValueError:
                        continue
                else:
                    continue
            
            try:
                dt = datetime.strptime(date_str, "%Y-%m-%d")
                if not in_date_range(dt):
                    continue
                date_key = dt.strftime('%d_%m')
            except ValueError:
                continue
            
            stocks_at_this_time = 0
            positions_dict = pos.get('positions', {})
            for symbol, info in positions_dict.items():
                if symbol != 'CASH' and isinstance(info, dict):
                    shares = info.get('shares', 0)
                    if shares > 0:
                        stocks_at_this_time += 1
            
            if date_key not in date_to_stocks_count:
                date_to_stocks_count[date_key] = []
            date_to_stocks_count[date_key].append(stocks_at_this_time)
        
        for date_key, stocks_count_per_time in date_to_stocks_count.items():
            if stocks_count_per_time:
                avg_stocks = round(sum(stocks_count_per_time) / len(stocks_count_per_time))
                model_attention[model_sig][date_key] = avg_stocks
            else:
                model_attention[model_sig][date_key] = 0
    
    return model_attention


def plot_model_attention_by_date(model_attention: Dict[str, Dict[str, int]], output_filename: str = "model_attention_by_date.png", title_prefix: str = "Model Stock Attention by Date", models_config: Dict = None):
    """ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹åœ¨ä¸åŒæ—¥æœŸçš„å…³æ³¨åº¦ï¼ˆæŒæœ‰è‚¡ç¥¨æ•°ï¼‰"""
    if not model_attention:
        print("âš  No model attention data available")
        return
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®š models_configï¼Œä½¿ç”¨å…¨å±€ MODELS
    if models_config is None:
        models_config = MODELS
    
    # è·å–æ‰€æœ‰æ—¥æœŸ
    all_dates = set()
    for date_dict in model_attention.values():
        all_dates.update(date_dict.keys())
    all_dates = sorted(list(all_dates), 
                       key=lambda x: datetime.strptime(x, '%d_%m'))  # æŒ‰æ—¥æœŸæ’åº
    
    # åŠ¨æ€ç”Ÿæˆæ ‡é¢˜ï¼šæ ¹æ®å®é™…æ—¥æœŸèŒƒå›´
    if all_dates:
        first_date = datetime.strptime(all_dates[0], '%d_%m')
        last_date = datetime.strptime(all_dates[-1], '%d_%m')
        if first_date.month == last_date.month:
            title_date_range = f"Jan {first_date.day}-{last_date.day}, 2026"
        else:
            title_date_range = f"{first_date.strftime('%b %d')}-{last_date.strftime('%b %d')}, 2026"
    else:
        title_date_range = "Jan 12-16, 2026"  # é»˜è®¤å€¼
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # æŸ±çŠ¶å›¾å‚æ•°
    x = np.arange(len(all_dates))
    width = 0.15
    
    # ä¸ºæ¯ä¸ªæ¨¡å‹ç»˜åˆ¶æŸ±çŠ¶å›¾
    model_sigs = sorted(model_attention.keys())
    for idx, model_sig in enumerate(model_sigs):
        stocks_count = [model_attention.get(model_sig, {}).get(date, 0) 
                        for date in all_dates]
        label = models_config.get(model_sig, {}).get("label", model_sig)
        color = models_config.get(model_sig, {}).get("color", "#666666")
        
        ax.bar(x + idx * width, stocks_count,
               width=width,
               label=label,
               color=color,
               alpha=0.8,
               edgecolor='black',
               linewidth=0.5)
    
    # è®¾ç½®xè½´æ ‡ç­¾
    date_labels = [d.replace('_', '-') for d in all_dates]
    ax.set_xticks(x + width * 2)
    ax.set_xticklabels(date_labels, fontsize=12, fontweight='bold')
    
    # æ ¼å¼åŒ–
    ax.set_xlabel('Date', fontsize=14, fontweight='bold')
    ax.set_ylabel('Number of Stocks Held', fontsize=14, fontweight='bold')
    ax.set_title(f'{title_prefix} ({title_date_range})', 
                fontsize=18, fontweight='bold', pad=20)
    ax.grid(True, alpha=0.3, axis='y', linestyle='--', linewidth=0.8)
    
    # åŠ¨æ€è®¾ç½®yè½´èŒƒå›´
    max_stocks = 0
    for date_dict in model_attention.values():
        max_stocks = max(max_stocks, max(date_dict.values(), default=0))
    y_max = max(6, max_stocks + 1)
    ax.set_ylim(0, y_max)
    ax.set_yticks(range(0, y_max + 1))
    
    # å›¾ä¾‹
    ax.legend(loc='upper left', fontsize=11, framealpha=0.95, edgecolor='gray')
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / output_filename
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"âœ“ Saved: {output_path}")
    plt.close()


def plot_stock_attention(attention_data: Dict[datetime, Dict[str, int]], output_filename: str = "stock_attention.png", title_prefix: str = "Stock Attention Over Time"):
    """ç»˜åˆ¶è‚¡ç¥¨å…³æ³¨åº¦å †ç§¯é¢ç§¯å›¾"""
    if not attention_data:
        print("âš  No stock attention data available")
        return
    
    # æ’åºæ—¶é—´
    times = sorted(attention_data.keys())
    
    # åŠ¨æ€ç”Ÿæˆæ ‡é¢˜ï¼šæ ¹æ®å®é™…æ—¥æœŸèŒƒå›´
    if times:
        first_date = times[0]
        last_date = times[-1]
        if first_date.month == last_date.month:
            title_date_range = f"{first_date.strftime('%b %d')}-{last_date.day}, {first_date.year}"
        else:
            title_date_range = f"{first_date.strftime('%b %d')}-{last_date.strftime('%b %d')}, {first_date.year}"
    else:
        title_date_range = "Jan 12-16, 2026"  # é»˜è®¤å€¼
    
    # è·å–æ‰€æœ‰è‚¡ç¥¨ç¬¦å·
    all_stocks = set()
    for stock_dict in attention_data.values():
        all_stocks.update(stock_dict.keys())
    all_stocks = sorted(list(all_stocks))
    
    # æ„å»ºæ•°æ®çŸ©é˜µ
    attention_matrix = []
    for stock in all_stocks:
        stock_attention = [attention_data[t].get(stock, 0) for t in times]
        attention_matrix.append(stock_attention)
    
    # ç”Ÿæˆé¢œè‰²åˆ—è¡¨ï¼ˆä¸º10æ”¯è‚¡ç¥¨åˆ†é…é¢œè‰²ï¼‰
    colors = plt.cm.tab20(np.linspace(0, 1, len(all_stocks)))
    
    # åˆ›å»ºå †ç§¯é¢ç§¯å›¾
    fig, ax = plt.subplots(figsize=(16, 8))
    
    # æ—¶é—´è½´ç´¢å¼•
    x_indices = np.arange(len(times))
    
    # ç»˜åˆ¶å †ç§¯é¢ç§¯
    ax.stackplot(x_indices, attention_matrix,
                labels=all_stocks,
                colors=colors,
                alpha=0.8,
                edgecolor='white',
                linewidth=0.5)
    
    # è®¾ç½®xè½´æ ‡ç­¾
    x_labels = [t.strftime('%m-%d\n%H:%M') for t in times]
    ax.set_xticks(x_indices)
    ax.set_xticklabels(x_labels, rotation=45, ha='right')
    
    # æ ¼å¼åŒ–
    ax.set_xlabel('Date & Time', fontsize=14, fontweight='bold')
    ax.set_ylabel('Number of Models Holding', fontsize=14, fontweight='bold')
    ax.set_title(f'{title_prefix} ({title_date_range})', 
                fontsize=18, fontweight='bold', pad=20)
    ax.grid(True, alpha=0.3, axis='y', linestyle='--', linewidth=0.8)
    
    # è®¡ç®—å®é™…æ•°æ®çš„æœ€å¤§å€¼ï¼ˆæ¯ä¸ªæ—¶é—´ç‚¹çš„æ€»å’Œï¼‰
    max_total = 0
    for t in times:
        total = sum(attention_data[t].values())
        max_total = max(max_total, total)
    
    # åŠ¨æ€è®¾ç½®yè½´èŒƒå›´ï¼šä½¿ç”¨å®é™…æœ€å¤§å€¼ + 1
    y_max = max_total + 1
    ax.set_ylim(0, y_max)
    ax.set_yticks(range(0, y_max + 1))
    
    # å›¾ä¾‹ï¼ˆæ”¾åœ¨å³ä¾§ï¼‰
    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, 
             ncol=1, framealpha=0.95, edgecolor='gray')
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / output_filename
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"âœ“ Saved: {output_path}")
    plt.close()


def plot_weekly_pnl(pnl_data: Dict[str, List[Tuple[datetime, float, float]]], 
                     title: str, output_filename: str, model_dict: Dict = None):
    """ç»˜åˆ¶ PnL å¯¹æ¯”å›¾ï¼ˆé€šç”¨å‡½æ•°ï¼‰"""
    if model_dict is None:
        model_dict = MODELS
    
    fig, ax = plt.subplots(figsize=(16, 9))
    
    # æ”¶é›†æ‰€æœ‰æ—¶é—´ç‚¹ç”¨äºåˆ›å»ºç»Ÿä¸€çš„xè½´æ ‡ç­¾
    all_times = set()
    for data_points in pnl_data.values():
        for dt, _, _ in data_points:
            all_times.add(dt)
    
    # æŒ‰æ—¶é—´æ’åºå¹¶åˆ›å»ºç´¢å¼•æ˜ å°„
    sorted_times = sorted(all_times)
    time_to_index = {dt: idx for idx, dt in enumerate(sorted_times)}
    
    # åŠ¨æ€ç”Ÿæˆæ—¥æœŸèŒƒå›´ç”¨äºæ ‡é¢˜
    if sorted_times:
        first_date = sorted_times[0]
        last_date = sorted_times[-1]
        if first_date.month == last_date.month:
            date_range = f"{first_date.strftime('%b %d')}-{last_date.day}, {first_date.year}"
        else:
            date_range = f"{first_date.strftime('%b %d')}-{last_date.strftime('%b %d')}, {first_date.year}"
        # æ›¿æ¢æ ‡é¢˜ä¸­çš„ "Date Range" å ä½ç¬¦
        title = title.replace('Date Range', date_range)
    
    for model_sig, data_points in pnl_data.items():
        if not data_points:
            continue
        
        # ä½¿ç”¨ç­‰é—´è·çš„ç´¢å¼•ä½œä¸ºxåæ ‡
        x_indices = np.array([time_to_index[dt] for dt, _, _ in data_points])
        returns = np.array([return_pct for _, _, return_pct in data_points])
        
        # å»é™¤é‡å¤çš„xåæ ‡ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªï¼‰
        unique_indices = []
        unique_returns = []
        seen = set()
        for x, y in zip(x_indices, returns):
            if x not in seen:
                unique_indices.append(x)
                unique_returns.append(y)
                seen.add(x)
        
        x_indices = np.array(unique_indices)
        returns = np.array(unique_returns)
        
        # è·å–æ¨¡å‹é…ç½®ä¿¡æ¯
        model_info = model_dict.get(model_sig, model_dict.get(model_sig, MODELS.get(model_sig, {"color": "#999999", "label": model_sig})))
        
        # ä½¿ç”¨æ ·æ¡æ’å€¼åˆ›å»ºå¹³æ»‘æ›²çº¿
        if len(x_indices) > 3:  # æ ·æ¡æ’å€¼è‡³å°‘éœ€è¦4ä¸ªç‚¹
            x_smooth = np.linspace(x_indices.min(), x_indices.max(), 300)
            spl = make_interp_spline(x_indices, returns, k=3)
            returns_smooth = spl(x_smooth)
            ax.plot(x_smooth, returns_smooth,
                   color=model_info["color"],
                   linewidth=3,
                   linestyle='-',
                   alpha=0.9,
                   label=model_info["label"])
        else:
            ax.plot(x_indices, returns,
                   color=model_info["color"],
                   linewidth=3,
                   linestyle='-',
                   alpha=0.9,
                   label=model_info["label"])
        
        # æ·»åŠ æ•°æ®ç‚¹æ ‡è®°
        ax.scatter(x_indices, returns,
                  color=model_info["color"],
                  s=50,
                  alpha=0.6,
                  zorder=5)
    
    # æ·»åŠ åŸºå‡†çº¿å’Œå›¾ä¾‹
    ax.axhline(y=0, color='gray', linestyle='--', linewidth=1.5, alpha=0.7, label='Break-even', zorder=1)
    ax.legend(loc='best', fontsize=12, framealpha=0.95, edgecolor='gray')
    
    # æ ¼å¼åŒ–
    ax.set_xlabel('Date & Time', fontsize=14, fontweight='bold')
    ax.set_ylabel('Return (%)', fontsize=14, fontweight='bold')
    ax.set_title(title, fontsize=18, fontweight='bold', pad=20)
    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)
    
    # è®¾ç½®xè½´å’Œyè½´æ ¼å¼
    x_positions = list(range(len(sorted_times)))
    x_labels = [dt.strftime('%m-%d\n%H:%M') for dt in sorted_times]
    ax.set_xticks(x_positions)
    ax.set_xticklabels(x_labels, rotation=45, ha='right')
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.2f}%'))
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / output_filename
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"âœ“ Saved: {output_path}")
    plt.close()


def plot_weekly_pnl_unrealized(pnl_data: Dict[str, List[Tuple[datetime, float, float]]], model_dict: Dict = None, version: str = ""):
    """ç»˜åˆ¶ Unrealized PnL å¯¹æ¯”å›¾ï¼ˆä½¿ç”¨å¸‚åœºä»·æ ¼ï¼Œæµ®åŠ¨ç›ˆäºï¼‰"""
    if model_dict is None:
        model_dict = MODELS
    
    version_suffix = f"_{version}" if version else ""
    filename = f'pnl_weekly_unrealized{version_suffix}.png'
    
    plot_weekly_pnl(pnl_data, 
                     'Weekly Unrealized PnL Comparison (Market Price, Date Range)',
                     filename,
                     model_dict)


def plot_weekly_pnl_realized(pnl_data: Dict[str, List[Tuple[datetime, float, float]]], model_dict: Dict = None, version: str = ""):
    """ç»˜åˆ¶ Realized PnL å¯¹æ¯”å›¾ï¼ˆä½¿ç”¨æˆæœ¬ä»·ï¼Œå·²å®ç°æƒç›Šï¼‰"""
    if model_dict is None:
        model_dict = MODELS
    
    version_suffix = f"_{version}" if version else ""
    filename = f'pnl_weekly_realized{version_suffix}.png'
    
    plot_weekly_pnl(pnl_data,
                     'Weekly Realized PnL Comparison (Cost Price, Date Range)',
                     filename,
                     model_dict)


def generate_summary_stats(pnl_data: Dict[str, List[Tuple[datetime, float, float]]]) -> str:
    """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
    summary_lines = ["## ğŸ“Š Performance Summary\n"]
    summary_lines.append("| Model | Latest Return | Max Return | Min Return | Volatility |")
    summary_lines.append("|-------|---------------|------------|------------|------------|")
    
    for model_sig, data_points in sorted(pnl_data.items()):
        if not data_points:
            continue
        
        returns = [r for _, _, r in data_points]
        latest_return = returns[-1] if returns else 0
        max_return = max(returns) if returns else 0
        min_return = min(returns) if returns else 0
        volatility = np.std(returns) if len(returns) > 1 else 0
        
        summary_lines.append(
            f"| {MODELS[model_sig]['label']} | "
            f"{latest_return:.2f}% | "
            f"{max_return:.2f}% | "
            f"{min_return:.2f}% | "
            f"{volatility:.2f}% |"
        )
    
    return "\n".join(summary_lines)


def calculate_etf_price_series() -> List[Tuple[datetime, float]]:
    """
    è®¡ç®—10åªè‚¡ç¥¨çš„ç­‰æƒé‡ETFä»·æ ¼åºåˆ—
    ä» ai_stock_data.json ä¸­è·å–æ¯åªè‚¡ç¥¨çš„ä»·æ ¼æ•°æ®ï¼ˆä»… 2026-01-12 åˆ° 2026-01-20ï¼‰ï¼Œç­‰æƒé‡æ±‚å¹³å‡
    æ¯å¤©ä¿ç•™3ä¸ªå†³ç­–æ—¶ç‚¹ï¼š10:30, 11:30, 14:00
    è¿”å›: [(timestamp, etf_price), ...]
    """
    stock_data_path = PROJECT_ROOT / "data_flow" / "ai_stock_data.json"
    if not stock_data_path.exists():
        print("âš ï¸ Warning: ai_stock_data.json not found, skipping ETF calculation")
        return []
    
    try:
        with open(stock_data_path, 'r', encoding='utf-8') as f:
            full_data = json.load(f)
    except Exception as e:
        print(f"âš ï¸ Warning: Failed to read ai_stock_data.json: {e}")
        return []
    
    # æ—¥æœŸèŒƒå›´é™åˆ¶
    start_date = DATE_FILTER_START
    end_date = DATE_FILTER_END
    
    # å†³ç­–æ—¶ç‚¹ï¼ˆå’Œå‰é¢ä¸¤ä¸ªå›¾ä¿æŒä¸€è‡´ï¼‰
    decision_times = ["10:30:00", "11:30:00", "14:00:00"]
    
    # ä¸ºæ¯åªè‚¡ç¥¨æ”¶é›†å†å²ä»·æ ¼æ•°æ®
    stock_prices = {symbol: {} for symbol in ETF_STOCKS}
    
    for symbol in ETF_STOCKS:
        if symbol not in full_data:
            print(f"âš ï¸ Warning: {symbol} not found in ai_stock_data.json")
            continue
        
        stock_data = full_data[symbol]
        if not isinstance(stock_data, dict):
            continue
        
        # ä¼˜å…ˆä½¿ç”¨å°æ—¶çº¿è¡Œæƒ…ï¼Œå…¶æ¬¡æ˜¯æ—¥çº¿è¡Œæƒ…
        price_data = stock_data.get('å°æ—¶çº¿è¡Œæƒ…') or stock_data.get('æ—¥çº¿è¡Œæƒ…') or []
        
        for candle in price_data:
            # æ—¶é—´å­—æ®µå¯èƒ½æ˜¯ 'date' æˆ– 'time'
            timestamp = candle.get('date') or candle.get('time')
            close_price = float(candle.get('close', 0))
            
            if timestamp and close_price > 0:
                try:
                    dt = datetime.strptime(timestamp[:19], '%Y-%m-%d %H:%M:%S')
                    # åªä¿ç•™ 2026-01-12 åˆ° 2026-01-20 çš„æ•°æ®
                    if start_date <= dt <= end_date:
                        # åªä¿ç•™å†³ç­–æ—¶ç‚¹çš„æ•°æ®
                        time_str = dt.strftime('%H:%M:%S')
                        if time_str in decision_times:
                            stock_prices[symbol][timestamp] = close_price
                except:
                    continue
    
    # åˆå¹¶æ‰€æœ‰æ—¶é—´æˆ³
    all_timestamps = set()
    for prices_dict in stock_prices.values():
        all_timestamps.update(prices_dict.keys())
    
    if not all_timestamps:
        print("âš ï¸ Warning: No price data found for ETF stocks in date range 2026-01-12 to 2026-01-20")
        return []
    
    # æ’åºæ—¶é—´æˆ³å¹¶è®¡ç®—æ¯ä¸ªæ—¶åˆ»çš„ç­‰æƒé‡ETFä»·æ ¼
    sorted_timestamps = sorted(all_timestamps)
    etf_series = []
    
    for ts in sorted_timestamps:
        prices = []
        for symbol in ETF_STOCKS:
            if ts in stock_prices[symbol]:
                prices.append(stock_prices[symbol][ts])
        
        if prices:  # åªè¦æœ‰æ•°æ®å°±è®¡ç®—å¹³å‡
            avg_price = np.mean(prices)
            # è§£ææ—¶é—´æˆ³
            try:
                dt = datetime.strptime(ts[:19], '%Y-%m-%d %H:%M:%S')
            except:
                continue
            
            etf_series.append((dt, avg_price))
    
    print(f"âœ“ ETF series: {len(etf_series)} data points from {etf_series[0][0]} to {etf_series[-1][0]}")
    
    return etf_series


def calculate_etf_return_series(etf_series: List[Tuple[datetime, float]]) -> Dict[str, List[Tuple[datetime, float]]]:
    """
    è®¡ç®—ETFçš„æ”¶ç›Šç‡åºåˆ—
    ä»¥ 2026-01-12 ç¬¬ä¸€ä¸ªä»·æ ¼ä½œä¸ºåŸºå‡†ä»·æ ¼ï¼ˆåˆå§‹ä»·æ ¼ï¼‰
    è¿”å›: {
        'etf': [(datetime, etf_price), ...],
        'return_pct': [(datetime, return_pct), ...]
    }
    """
    if not etf_series:
        return {}
    
    # æŒ‰æ—¶é—´æ’åº
    etf_series = sorted(etf_series, key=lambda x: x[0])
    
    # è®¡ç®—æ”¶ç›Šç‡ï¼ˆç›¸å¯¹ 2026-01-12 çš„ç¬¬ä¸€ä¸ªä»·æ ¼ä½œä¸ºåˆå§‹ä»·æ ¼ï¼‰
    initial_price = etf_series[0][1]
    
    if initial_price <= 0:
        print(f"âš ï¸ Warning: Invalid initial price {initial_price}")
        return {}
    
    return_pct_series = []
    
    for dt, price in etf_series:
        if price > 0:
            # æ”¶ç›Šç‡ = (å½“å‰ä»·æ ¼ - åˆå§‹ä»·æ ¼) / åˆå§‹ä»·æ ¼ * 100
            return_pct = ((price - initial_price) / initial_price) * 100
        else:
            return_pct = 0
        return_pct_series.append((dt, return_pct))
    
    print(f"âœ“ ETF return series: initial_price={initial_price:.2f}, final_price={etf_series[-1][1]:.2f}, final_return={return_pct_series[-1][1]:.2f}%")
    
    return {
        'etf': etf_series,
        'return_pct': return_pct_series
    }


def plot_etf_performance(etf_data: Dict):
    """
    ç»˜åˆ¶10åªè‚¡ç¥¨ç­‰æƒé‡ETFçš„è¡¨ç°å›¾è¡¨
    åŒ…å«: ETFä»·æ ¼ã€æ”¶ç›Šç‡ï¼ˆä½¿ç”¨æ ·æ¡æ›²çº¿ï¼Œæ¯å¤©3ä¸ªå†³ç­–ç‚¹ï¼‰
    """
    if not etf_data or 'return_pct' not in etf_data:
        print("âš ï¸ Warning: No ETF data to plot")
        return
    
    etf_series = etf_data.get('etf', [])
    return_series = etf_data.get('return_pct', [])
    
    if not etf_series or not return_series:
        return
    
    # æŒ‰æ—¶é—´æ’åº
    return_series = sorted(return_series, key=lambda x: x[0])
    etf_series = sorted(etf_series, key=lambda x: x[0])
    
    # æ”¶é›†æ‰€æœ‰æ—¶é—´ç‚¹
    all_times = set([dt for dt, _ in return_series])
    sorted_times = sorted(all_times)
    time_to_index = {dt: idx for idx, dt in enumerate(sorted_times)}
    
    # æå–æ•°æ®ï¼ˆä¿ç•™æ‰€æœ‰å†³ç­–æ—¶ç‚¹ï¼‰
    x_indices = [time_to_index[dt] for dt, _ in return_series]
    returns = [ret for _, ret in return_series]
    prices = [price for _, price in etf_series]
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 1, figsize=(14, 10))
    fig.suptitle('Equal-Weight ETF Performance (10 Stocks)', fontsize=16, fontweight='bold', y=0.995)
    
    # å›¾1: ETFä»·æ ¼èµ°åŠ¿ï¼ˆä½¿ç”¨æ ·æ¡æ›²çº¿ï¼‰
    ax1 = axes[0]
    x_indices_arr = np.array(x_indices)
    prices_arr = np.array(prices)
    
    if len(x_indices) > 3:
        x_smooth = np.linspace(min(x_indices), max(x_indices), 300)
        spl = make_interp_spline(x_indices_arr, prices_arr, k=3)
        prices_smooth = spl(x_smooth)
        ax1.plot(x_smooth, prices_smooth, linewidth=2.5, color='#2E86AB', label='ETF Value')
    else:
        ax1.plot(x_indices, prices, 'o-', linewidth=2.5, color='#2E86AB', label='ETF Value', markersize=4)
    
    ax1.scatter(x_indices, prices, color='#2E86AB', s=30, alpha=0.6, zorder=5)
    ax1.set_ylabel('Value (Â¥)', fontsize=11)
    ax1.set_title('Equal-Weight ETF Value Trend', fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3, linestyle='--')
    ax1.legend(fontsize=10)
    
    # å›¾2: æ”¶ç›Šç‡èµ°åŠ¿ï¼ˆä½¿ç”¨æ ·æ¡æ›²çº¿ï¼‰
    ax2 = axes[1]
    returns_arr = np.array(returns)
    
    if len(x_indices) > 3:
        x_smooth = np.linspace(min(x_indices), max(x_indices), 300)
        spl = make_interp_spline(x_indices_arr, returns_arr, k=3)
        returns_smooth = spl(x_smooth)
        ax2.plot(x_smooth, returns_smooth, linewidth=2.5, color='#4CAF50', label='Return')
    else:
        ax2.plot(x_indices, returns, 'o-', linewidth=2.5, color='#4CAF50', label='Return', markersize=4)
    
    ax2.scatter(x_indices, returns, color='#4CAF50', s=30, alpha=0.6, zorder=5)
    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)
    ax2.set_xlabel('Date & Time', fontsize=11)
    ax2.set_ylabel('Return (%)', fontsize=11)
    ax2.set_title('Equal-Weight ETF Return Trend', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3, linestyle='--', axis='y')
    ax2.legend(fontsize=10)
    
    # è®¾ç½®xè½´æ ‡ç­¾ï¼ˆæ˜¾ç¤ºæ—¥æœŸå’Œæ—¶é—´ï¼Œå’Œå‰ä¸¤ä¸ªå›¾ä¸€æ ·ï¼‰
    x_labels = [dt.strftime('%m-%d\n%H:%M') for dt in sorted_times]
    x_positions = list(range(len(sorted_times)))
    
    ax1.set_xticks(x_positions)
    ax1.set_xticklabels([])  # ä¸Šå›¾ä¸æ˜¾ç¤ºæ ‡ç­¾
    ax2.set_xticks(x_positions)
    ax2.set_xticklabels(x_labels, rotation=45, ha='right')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_file = OUTPUT_DIR / "etf_performance.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved: {output_file}")
    plt.close()


def fetch_star50_benchmark_series() -> List[Tuple[datetime, float]]:
    """
    ä» nav_history.json è¯»å– Star50 benchmark æ•°æ®
    è¿”å›: [(datetime, return_pct), ...]
    """
    nav_history_path = PROJECT_ROOT / "data_flow" / "star50_benchmark" / "nav_history.json"
    
    if not nav_history_path.exists():
        print(f"âš ï¸ Warning: nav_history.json not found at {nav_history_path}")
        return []
    
    try:
        with open(nav_history_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        nav_history = data.get('nav_history', [])
        if not nav_history:
            print("âš ï¸ Warning: nav_history is empty")
            return []
        
        # å†³ç­–æ—¶ç‚¹ï¼ˆæ¯å¤©3ä¸ªæ—¶é—´ç‚¹ï¼‰
        decision_times = ["10:30:00", "11:30:00", "14:00:00"]
        
        star50_series = []
        current_date = None
        time_index_in_day = 0
        
        for entry in nav_history:
            date_str = entry.get('date', '')
            pnl_pct = entry.get('pnl_pct', 0.0)
            
            if not date_str:
                continue
            
            try:
                # è§£ææ—¥æœŸ (æ ¼å¼: "20260112")
                date_obj = datetime.strptime(date_str, "%Y%m%d")
                
                # å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®æ—¶é—´ç´¢å¼•
                if current_date != date_str:
                    current_date = date_str
                    time_index_in_day = 0
                
                # æ ¹æ®å½“å¤©çš„æ—¶é—´ç´¢å¼•ç¡®å®šå…·ä½“æ—¶é—´
                if time_index_in_day < len(decision_times):
                    time_str = decision_times[time_index_in_day]
                    time_parts = time_str.split(':')
                    dt = date_obj.replace(
                        hour=int(time_parts[0]),
                        minute=int(time_parts[1]),
                        second=int(time_parts[2])
                    )
                    
                    # æ£€æŸ¥æ—¥æœŸæ˜¯å¦åœ¨èŒƒå›´å†…
                    if in_date_range(dt):
                        star50_series.append((dt, float(pnl_pct)))
                    
                    time_index_in_day += 1
                    
            except (ValueError, KeyError) as e:
                print(f"âš ï¸ Warning: Failed to parse entry {entry}: {e}")
                continue
        
        # æŒ‰æ—¶é—´æ’åº
        star50_series = sorted(star50_series, key=lambda x: x[0])
        
        if star50_series:
            print(f"âœ“ Star50 benchmark series: {len(star50_series)} data points from {star50_series[0][0]} to {star50_series[-1][0]}")
        
        return star50_series
        
    except Exception as e:
        print(f"âš ï¸ Warning: Failed to read nav_history.json: {e}")
        import traceback
        traceback.print_exc()
        return []


def plot_etf_vs_models(etf_data: Dict, unrealized_pnl_data: Dict, star50_series: List[Tuple[datetime, float]] = None):
    """
    å¯¹æ¯”ETFã€Star50 benchmarkä¸å„æ¨¡å‹çš„è¡¨ç°ï¼ˆä½¿ç”¨æ ·æ¡æ›²çº¿ï¼Œæ¯å¤©3ä¸ªå†³ç­–ç‚¹ï¼‰
    ä½¿ç”¨ Unrealized PnLï¼ˆå¸‚åœºä»·æ ¼ï¼‰æ¥å±•ç°æ¨¡å‹çš„å®é™…æŠ•èµ„æ”¶ç›Šï¼ŒåŒ…å«ä¹°å…¥æ—¶æœºæ•ˆæœ
    """
    if not etf_data or not unrealized_pnl_data:
        print("âš ï¸ Warning: Missing data for comparison chart")
        return
    
    return_series = etf_data.get('return_pct', [])
    if not return_series:
        return
    
    return_series = sorted(return_series, key=lambda x: x[0])
    
    # æ”¶é›†æ‰€æœ‰æ—¶é—´ç‚¹
    all_times = set()
    for dt, _ in return_series:
        all_times.add(dt)
    for pnl_list in unrealized_pnl_data.values():
        for dt, _, _ in pnl_list:
            all_times.add(dt)
    
    # Add Star50 benchmark times if available
    if star50_series:
        for dt, _ in star50_series:
            all_times.add(dt)
    
    sorted_times = sorted(all_times)
    time_to_index = {dt: idx for idx, dt in enumerate(sorted_times)}
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # Star50 benchmark æ•°æ®å¤„ç†ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if star50_series:
        star50_x_indices = [time_to_index[dt] for dt, _ in star50_series if dt in time_to_index]
        star50_returns = [ret for dt, ret in star50_series if dt in time_to_index]
        
        if star50_x_indices:
            star50_x_indices = np.array(star50_x_indices)
            star50_returns = np.array(star50_returns)
            
            # ç»˜åˆ¶Star50 benchmarkï¼ˆä½¿ç”¨æ ·æ¡æ›²çº¿ï¼Œç´«è‰²ç³»ï¼‰
            if len(star50_x_indices) > 3:
                x_smooth = np.linspace(star50_x_indices.min(), star50_x_indices.max(), 300)
                spl = make_interp_spline(star50_x_indices, star50_returns, k=3)
                returns_smooth = spl(x_smooth)
                ax.plot(x_smooth, returns_smooth, linewidth=3.5, color='#9B59B6', 
                        label='Star50 benchmark', zorder=5, linestyle='-.')
            else:
                ax.plot(star50_x_indices, star50_returns, 'o-', linewidth=3, color='#9B59B6',
                        label='Star50 benchmark', markersize=5, zorder=5, linestyle='-.')
            
            ax.scatter(star50_x_indices, star50_returns, color='#9B59B6', s=50, alpha=0.7, zorder=6)
    
    # ETFæ•°æ®å¤„ç†ï¼ˆä¿ç•™æ‰€æœ‰å†³ç­–æ—¶ç‚¹ï¼‰
    etf_x_indices = [time_to_index[dt] for dt, _ in return_series]
    etf_returns = [ret for _, ret in return_series]
    
    etf_x_indices = np.array(etf_x_indices)
    etf_returns = np.array(etf_returns)
    
    # ç»˜åˆ¶ETFï¼ˆä½¿ç”¨æ ·æ¡æ›²çº¿ï¼Œæ”¹ç”¨è“è‰²ç³»ï¼‰
    if len(etf_x_indices) > 3:
        x_smooth = np.linspace(etf_x_indices.min(), etf_x_indices.max(), 300)
        spl = make_interp_spline(etf_x_indices, etf_returns, k=3)
        returns_smooth = spl(x_smooth)
        ax.plot(x_smooth, returns_smooth, linewidth=3.5, color='#2E86AB', 
                label='Equal-Weight ETF (10 Stocks)', zorder=5)
    else:
        ax.plot(etf_x_indices, etf_returns, 'o-', linewidth=3, color='#2E86AB',
                label='Equal-Weight ETF (10 Stocks)', markersize=5, zorder=5)
    
    ax.scatter(etf_x_indices, etf_returns, color='#2E86AB', s=50, alpha=0.7, zorder=6)
    
    # ç»˜åˆ¶å„æ¨¡å‹ï¼ˆä½¿ç”¨æ ·æ¡æ›²çº¿ï¼‰
    for model_sig, pnl_list in unrealized_pnl_data.items():
        if not pnl_list:
            continue
        
        pnl_list = sorted(pnl_list, key=lambda x: x[0])
        
        # æå–æ•°æ®ï¼ˆä¿ç•™æ‰€æœ‰å†³ç­–æ—¶ç‚¹ï¼‰
        model_x_indices = []
        model_returns = []
        
        for dt, _, ret_pct in pnl_list:
            if dt in time_to_index:
                idx = time_to_index[dt]
                model_x_indices.append(idx)
                model_returns.append(ret_pct)
        
        if not model_x_indices:
            continue
        
        model_x_indices = np.array(model_x_indices)
        model_returns = np.array(model_returns)
        
        model_info = MODELS.get(model_sig, {})
        label = model_info.get('label', model_sig)
        color = model_info.get('color', '#000000')
        
        # ä½¿ç”¨æ ·æ¡æ›²çº¿
        if len(model_x_indices) > 3:
            x_smooth = np.linspace(model_x_indices.min(), model_x_indices.max(), 300)
            spl = make_interp_spline(model_x_indices, model_returns, k=3)
            returns_smooth = spl(x_smooth)
            ax.plot(x_smooth, returns_smooth, linewidth=2.5, color=color, 
                    label=label, alpha=0.85, zorder=3)
        else:
            ax.plot(model_x_indices, model_returns, 'o-', linewidth=2, color=color, 
                    label=label, markersize=4, alpha=0.8, zorder=3)
        
        ax.scatter(model_x_indices, model_returns, color=color, s=30, alpha=0.5, zorder=4)
    
    ax.set_ylabel('Return (%)', fontsize=12)
    ax.set_title('AI Trading Models vs Equal-Weight ETF Performance', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.legend(fontsize=10, loc='best')
    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)
    
    # è®¾ç½®xè½´æ ‡ç­¾ï¼ˆå’Œå‰ä¸¤ä¸ªå›¾ä¸€æ ·ï¼‰
    x_labels = [dt.strftime('%m-%d\n%H:%M') for dt in sorted_times]
    x_positions = list(range(len(sorted_times)))
    ax.set_xticks(x_positions)
    ax.set_xticklabels(x_labels, rotation=45, ha='right')
    ax.set_xlabel('Date & Time', fontsize=12)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_file = OUTPUT_DIR / "etf_vs_models_comparison.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved: {output_file}")
    plt.close()


def plot_benchmarks_comparison(etf_data: Dict, lite_pnl_data: Dict, pro_pnl_data: Dict, star50_series: List[Tuple[datetime, float]] = None):
    """
    ç”ŸæˆLiteå’ŒProä¸¤ä¸ªç‰ˆæœ¬çš„benchmarkå¯¹æ¯”å›¾
    å·¦å›¾ï¼šLiteæ¨¡å‹ vs ETF vs Star50 benchmark
    å³å›¾ï¼šProæ¨¡å‹ vs ETF vs Star50 benchmark
    """
    if not etf_data:
        print("âš ï¸ Warning: Missing ETF data for benchmark comparison")
        return
    
    return_series = etf_data.get('return_pct', [])
    if not return_series:
        return
    
    return_series = sorted(return_series, key=lambda x: x[0])
    
    # åˆ›å»ºåŒå›¾è¡¨
    fig, axes = plt.subplots(1, 2, figsize=(18, 7))
    
    # ç»˜åˆ¶Liteç‰ˆæœ¬
    ax = axes[0]
    _plot_benchmark_single(ax, return_series, lite_pnl_data, "Lite Version", MODELS_LITE, star50_series)
    
    # ç»˜åˆ¶Proç‰ˆæœ¬
    ax = axes[1]
    _plot_benchmark_single(ax, return_series, pro_pnl_data, "Pro Version", MODELS_PRO, star50_series)
    
    plt.tight_layout()
    output_file = OUTPUT_DIR / "benchmarks_lite_vs_pro.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved: {output_file}")
    plt.close()


def plot_benchmarks_realized(etf_data: Dict, lite_realized: Dict, pro_realized: Dict, star50_series: List[Tuple[datetime, float]] = None):
    """
    ç”Ÿæˆ Lite å’Œ Pro ç‰ˆæœ¬çš„åŸºå‡†å¯¹æ¯”å›¾ï¼ˆä½¿ç”¨ Realized PnLï¼‰
    å·¦å›¾ï¼šLite realized vs ETF vs Star50 benchmark
    å³å›¾ï¼šPro realized vs ETF vs Star50 benchmark
    """
    if not etf_data:
        print("âš ï¸ Warning: Missing ETF data for realized benchmark comparison")
        return

    return_series = etf_data.get('return_pct', [])
    if not return_series:
        return

    return_series = sorted(return_series, key=lambda x: x[0])

    fig, axes = plt.subplots(1, 2, figsize=(18, 7))

    ax = axes[0]
    _plot_benchmark_single(ax, return_series, lite_realized, "Lite Version (Realized)", MODELS_LITE, star50_series)

    ax = axes[1]
    _plot_benchmark_single(ax, return_series, pro_realized, "Pro Version (Realized)", MODELS_PRO, star50_series)

    plt.tight_layout()
    output_file = OUTPUT_DIR / "benchmarks_lite_vs_pro_realized.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved: {output_file}")
    plt.close()


def _plot_benchmark_single(ax, etf_series, model_pnl_data, title_suffix, model_dict, star50_series=None):
    """
    ç»˜åˆ¶å•ä¸ªbenchmarkå¯¹æ¯”å›¾ï¼ˆLiteæˆ–Proï¼‰
    """
    # æ”¶é›†æ‰€æœ‰æ—¶é—´ç‚¹
    all_times = set()
    for dt, _ in etf_series:
        all_times.add(dt)
    for pnl_list in model_pnl_data.values():
        for dt, _, _ in pnl_list:
            all_times.add(dt)
    if star50_series:
        for dt, _ in star50_series:
            all_times.add(dt)
    
    sorted_times = sorted(all_times)
    time_to_index = {dt: idx for idx, dt in enumerate(sorted_times)}
    
    # ç»˜åˆ¶Star50 benchmark
    if star50_series:
        star50_x_indices = [time_to_index[dt] for dt, _ in star50_series if dt in time_to_index]
        star50_returns = [ret for dt, ret in star50_series if dt in time_to_index]
        
        if star50_x_indices:
            star50_x_indices = np.array(star50_x_indices)
            star50_returns = np.array(star50_returns)
            
            if len(star50_x_indices) > 3:
                x_smooth = np.linspace(star50_x_indices.min(), star50_x_indices.max(), 300)
                spl = make_interp_spline(star50_x_indices, star50_returns, k=3)
                returns_smooth = spl(x_smooth)
                ax.plot(x_smooth, returns_smooth, linewidth=3.5, color='#9B59B6', 
                        label='Star50 benchmark', zorder=5, linestyle='-.')
            else:
                ax.plot(star50_x_indices, star50_returns, 'o-', linewidth=3, color='#9B59B6',
                        label='Star50 benchmark', markersize=5, zorder=5, linestyle='-.')
            
            ax.scatter(star50_x_indices, star50_returns, color='#9B59B6', s=50, alpha=0.7, zorder=6)
    
    # ç»˜åˆ¶ETF
    etf_x_indices = [time_to_index[dt] for dt, _ in etf_series]
    etf_returns = [ret for _, ret in etf_series]
    
    etf_x_indices = np.array(etf_x_indices)
    etf_returns = np.array(etf_returns)
    
    if len(etf_x_indices) > 3:
        x_smooth = np.linspace(etf_x_indices.min(), etf_x_indices.max(), 300)
        spl = make_interp_spline(etf_x_indices, etf_returns, k=3)
        returns_smooth = spl(x_smooth)
        ax.plot(x_smooth, returns_smooth, linewidth=3.5, color='#2E86AB', 
                label='Equal-Weight ETF (10 Stocks)', zorder=5)
    
    ax.scatter(etf_x_indices, etf_returns, color='#2E86AB', s=50, alpha=0.7, zorder=6)
    
    # ç»˜åˆ¶æ¨¡å‹ï¼ˆä½¿ç”¨ç›¸åº”ç‰ˆæœ¬çš„é…ç½®ï¼‰
    for model_sig, pnl_list in model_pnl_data.items():
        if not pnl_list:
            continue
        
        pnl_list = sorted(pnl_list, key=lambda x: x[0])
        
        model_x_indices = []
        model_returns = []
        
        for dt, _, ret_pct in pnl_list:
            if dt in time_to_index:
                idx = time_to_index[dt]
                model_x_indices.append(idx)
                model_returns.append(ret_pct)
        
        if not model_x_indices:
            continue
        
        model_x_indices = np.array(model_x_indices)
        model_returns = np.array(model_returns)
        
        model_info = model_dict.get(model_sig, {})
        label = model_info.get('label', model_sig)
        color = model_info.get('color', '#000000')
        
        if len(model_x_indices) > 3:
            x_smooth = np.linspace(model_x_indices.min(), model_x_indices.max(), 300)
            spl = make_interp_spline(model_x_indices, model_returns, k=3)
            returns_smooth = spl(x_smooth)
            ax.plot(x_smooth, returns_smooth, linewidth=2.5, color=color, 
                    label=label, alpha=0.85, zorder=3)
        else:
            ax.plot(model_x_indices, model_returns, 'o-', linewidth=2, color=color, 
                    label=label, markersize=4, alpha=0.8, zorder=3)
        
        ax.scatter(model_x_indices, model_returns, color=color, s=30, alpha=0.5, zorder=4)
    
    ax.set_ylabel('Return (%)', fontsize=11)
    ax.set_title(f'{title_suffix}: Models vs Benchmarks', fontsize=13, fontweight='bold')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.legend(fontsize=9, loc='best')
    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)
    
    # è®¾ç½®xè½´æ ‡ç­¾
    x_labels = [dt.strftime('%m-%d\n%H:%M') for dt in sorted_times]
    x_positions = list(range(len(sorted_times)))
    ax.set_xticks(x_positions)
    ax.set_xticklabels(x_labels, rotation=45, ha='right', fontsize=9)
    ax.set_xlabel('Date & Time', fontsize=11)


def plot_model_version_comparison(lite_pnl_data: Dict, pro_pnl_data: Dict):
    """
    å¯¹æ¯”ä½é…ç‰ˆï¼ˆLiteï¼‰å’Œå‡çº§ç‰ˆï¼ˆProï¼‰æ¨¡å‹çš„è¡¨ç°
    æ˜¾ç¤ºåŒç³»åˆ—æ¨¡å‹çš„å‡çº§æ•ˆæœ
    """
    if not lite_pnl_data or not pro_pnl_data:
        print("âš ï¸ Warning: Missing data for model version comparison")
        return
    
    # æ”¶é›†æ‰€æœ‰æ—¶é—´ç‚¹
    all_times = set()
    for pnl_list in lite_pnl_data.values():
        for dt, _, _ in pnl_list:
            all_times.add(dt)
    for pnl_list in pro_pnl_data.values():
        for dt, _, _ in pnl_list:
            all_times.add(dt)
    
    sorted_times = sorted(all_times)
    time_to_index = {dt: idx for idx, dt in enumerate(sorted_times)}
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(1, 5, figsize=(20, 6))
    
    # å¯¹æ¯ä¸ªæ¨¡å‹ç³»åˆ—ç»˜åˆ¶å¯¹æ¯”
    model_names = list(MODEL_PAIRS.keys())
    
    for idx, (lite_model, ax) in enumerate(zip(model_names, axes)):
        pro_model = MODEL_PAIRS[lite_model]
        
        # è·å– Lite ç‰ˆæœ¬æ•°æ®
        if lite_model in lite_pnl_data:
            lite_list = lite_pnl_data[lite_model]
            lite_x_indices = []
            lite_returns = []
            for dt, _, ret_pct in lite_list:
                if dt in time_to_index:
                    lite_x_indices.append(time_to_index[dt])
                    lite_returns.append(ret_pct)
            
            if lite_x_indices:
                lite_x_indices = np.array(lite_x_indices)
                lite_returns = np.array(lite_returns)
                
                # ç»˜åˆ¶ Lite ç‰ˆæœ¬
                if len(lite_x_indices) > 3:
                    x_smooth = np.linspace(lite_x_indices.min(), lite_x_indices.max(), 300)
                    spl = make_interp_spline(lite_x_indices, lite_returns, k=3)
                    returns_smooth = spl(x_smooth)
                    ax.plot(x_smooth, returns_smooth, linewidth=2.5, color='#94A3B8', 
                            label='Lite', alpha=0.8, zorder=3)
                else:
                    ax.plot(lite_x_indices, lite_returns, 'o-', linewidth=2, color='#94A3B8',
                            label='Lite', markersize=4, alpha=0.8, zorder=3)
                
                ax.scatter(lite_x_indices, lite_returns, color='#94A3B8', s=30, alpha=0.5, zorder=4)
        
        # è·å– Pro ç‰ˆæœ¬æ•°æ®
        if pro_model in pro_pnl_data:
            pro_list = pro_pnl_data[pro_model]
            pro_x_indices = []
            pro_returns = []
            for dt, _, ret_pct in pro_list:
                if dt in time_to_index:
                    pro_x_indices.append(time_to_index[dt])
                    pro_returns.append(ret_pct)
            
            if pro_x_indices:
                pro_x_indices = np.array(pro_x_indices)
                pro_returns = np.array(pro_returns)
                
                # è·å–æ¨¡å‹é…ç½®ä¸­çš„é¢œè‰²
                lite_model_info = MODELS_LITE.get(lite_model, {})
                color = lite_model_info.get('color', '#000000')
                
                # ç»˜åˆ¶ Pro ç‰ˆæœ¬
                if len(pro_x_indices) > 3:
                    x_smooth = np.linspace(pro_x_indices.min(), pro_x_indices.max(), 300)
                    spl = make_interp_spline(pro_x_indices, pro_returns, k=3)
                    returns_smooth = spl(x_smooth)
                    ax.plot(x_smooth, returns_smooth, linewidth=2.5, color=color, 
                            label='Pro', alpha=0.9, zorder=3)
                else:
                    ax.plot(pro_x_indices, pro_returns, 'o-', linewidth=2, color=color,
                            label='Pro', markersize=4, alpha=0.9, zorder=3)
                
                ax.scatter(pro_x_indices, pro_returns, color=color, s=30, alpha=0.6, zorder=4)
        
        # è®¾ç½®å­å›¾å±æ€§
        ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)
        ax.grid(True, alpha=0.3, linestyle='--')
        ax.set_ylabel('Return (%)', fontsize=10)
        
        # ä½¿ç”¨ç®€çŸ­çš„æ ‡ç­¾
        lite_label = lite_model.split('-')[0].capitalize()
        ax.set_title(f'{lite_label}: Lite vs Pro', fontsize=11, fontweight='bold')
        ax.legend(fontsize=9, loc='best')
    
    # è®¾ç½® x è½´æ ‡ç­¾ï¼ˆä»…åœ¨æœ€åä¸€ä¸ªå­å›¾æ˜¾ç¤ºï¼‰
    x_labels = [dt.strftime('%m-%d\n%H:%M') if i % 3 == 0 else '' 
                for i, dt in enumerate(sorted_times)]
    x_positions = list(range(len(sorted_times)))
    
    for ax in axes:
        ax.set_xticks(x_positions)
        ax.set_xticklabels(x_labels, rotation=45, ha='right', fontsize=8)
        ax.set_xlabel('Date & Time', fontsize=9)
    
    fig.suptitle('Model Version Comparison: Lite vs Pro', fontsize=15, fontweight='bold', y=1.00)
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_file = OUTPUT_DIR / "model_version_comparison.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"âœ“ Saved: {output_file}")
    plt.close()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AStock Arena - PnL Visualization Generator")
    print("=" * 60)
    print()
    
    # 0. æå–ä¸¤ä¸ªç‰ˆæœ¬çš„æ¨¡å‹æ•°æ®
    print("ğŸ“¥ Extracting data for both model versions...\n")
    
    # æå– Lite ç‰ˆæœ¬çš„ Unrealized å’Œ Realized PnL
    print("  ğŸ“Š Lite models (Haiku, Chat, 5.1, 235b, Flash):")
    lite_unrealized_pnl = extract_unrealized_pnl_by_models(MODELS_LITE)
    lite_realized_pnl = extract_realized_pnl_by_models(MODELS_LITE)
    print(f"    âœ“ Loaded {len(lite_unrealized_pnl)} Lite models (unrealized)")
    print(f"    âœ“ Loaded {len(lite_realized_pnl)} Lite models (realized)\n")
    
    # æå– Pro ç‰ˆæœ¬çš„ Unrealized å’Œ Realized PnL
    print("  ğŸ“Š Pro models (Opus, Reasoner, 5.2, Max, 3-Pro):")
    pro_unrealized_pnl = extract_unrealized_pnl_by_models(MODELS_PRO)
    pro_realized_pnl = extract_realized_pnl_by_models(MODELS_PRO)
    print(f"    âœ“ Loaded {len(pro_unrealized_pnl)} Pro models (unrealized)")
    print(f"    âœ“ Loaded {len(pro_realized_pnl)} Pro models (realized)\n")
    
    # ä½¿ç”¨å½“å‰é€‰å®šçš„æ¨¡å‹ç‰ˆæœ¬è¿›è¡Œåç»­å¯è§†åŒ–
    if MODEL_VERSION == "lite":
        unrealized_pnl_data = lite_unrealized_pnl
        realized_pnl_data = lite_realized_pnl
    else:
        unrealized_pnl_data = pro_unrealized_pnl
        realized_pnl_data = pro_realized_pnl
    
    print(f"ğŸ“Œ Proceeding with {MODEL_VERSION.upper()} models for main visualizations\n")
    
    # 3. è®¡ç®—ç­‰æƒé‡ETF
    print("ğŸ“Š Calculating equal-weight ETF (10 stocks)...")
    etf_series = calculate_etf_price_series()
    if etf_series:
        print(f"âœ“ ETF price series: {len(etf_series)} data points")
        etf_data = calculate_etf_return_series(etf_series)
    else:
        etf_data = {}
        print("âš  Warning: Failed to calculate ETF")
    
    # 3.5 è·å–Star50 benchmarkæ•°æ®
    print("ğŸ“Š Fetching Star50 benchmark data...")
    star50_series = fetch_star50_benchmark_series()
    if not star50_series:
        print("âš  Warning: Failed to fetch Star50 benchmark data")
    
    # 4. ç”ŸæˆPnLå¯¹æ¯”å›¾ï¼ˆ4å¼ ï¼šLite Unrealizedã€Lite Realizedã€Pro Unrealizedã€Pro Realizedï¼‰
    print("\nğŸ“ˆ Generating Weekly PnL Charts (4 charts total):")
    
    if lite_unrealized_pnl:
        print("  ğŸ“Š Lite Unrealized PnL...")
        plot_weekly_pnl_unrealized(lite_unrealized_pnl, MODELS_LITE, "lite")
    
    if lite_realized_pnl:
        print("  ğŸ“Š Lite Realized PnL...")
        plot_weekly_pnl_realized(lite_realized_pnl, MODELS_LITE, "lite")
    
    if pro_unrealized_pnl:
        print("  ğŸ“Š Pro Unrealized PnL...")
        plot_weekly_pnl_unrealized(pro_unrealized_pnl, MODELS_PRO, "pro")
    
    if pro_realized_pnl:
        print("  ğŸ“Š Pro Realized PnL...")
        plot_weekly_pnl_realized(pro_realized_pnl, MODELS_PRO, "pro")
    
    # 5. ç”Ÿæˆå…¶ä»–å›¾è¡¨
    if etf_data:
        print("ğŸ“ˆ Generating ETF performance chart...")
        plot_etf_performance(etf_data)
        
        print("ğŸ“ˆ Generating ETF vs Models comparison chart (with Star50 benchmark)...")
        plot_etf_vs_models(etf_data, unrealized_pnl_data, star50_series)
    
    print("ğŸ“Š Generating stock attention charts (overall, Lite, Pro)...")
    attention_data_all = extract_stock_attention()
    plot_stock_attention(attention_data_all, "stock_attention.png", "Stock Attention Over Time (All Models)")

    attention_data_lite = extract_stock_attention(MODELS_LITE)
    plot_stock_attention(attention_data_lite, "stock_attention_lite.png", "Stock Attention Over Time (Lite)")

    attention_data_pro = extract_stock_attention(MODELS_PRO)
    plot_stock_attention(attention_data_pro, "stock_attention_pro.png", "Stock Attention Over Time (Pro)")
    
    print("ğŸ“Š Generating model attention by date charts (Lite, Pro)...")
    model_attention_lite = extract_model_attention_by_date(MODELS_LITE)
    plot_model_attention_by_date(model_attention_lite, "model_attention_by_date_lite.png", "Model Stock Attention by Date (Lite)", models_config=MODELS_LITE)

    model_attention_pro = extract_model_attention_by_date(MODELS_PRO)
    plot_model_attention_by_date(model_attention_pro, "model_attention_by_date_pro.png", "Model Stock Attention by Date (Pro)", models_config=MODELS_PRO)
    
    # 4.5 ç”Ÿæˆæ¨¡å‹ç‰ˆæœ¬å¯¹æ¯”å›¾
    print("ğŸ“ˆ Generating Model Version Comparison chart (Lite vs Pro)...")
    if lite_unrealized_pnl and pro_unrealized_pnl:
        plot_model_version_comparison(lite_unrealized_pnl, pro_unrealized_pnl)
    else:
        print("âš  Warning: Insufficient data for model version comparison")
    
    # 4.6 ç”ŸæˆLiteå’ŒProçš„benchmarkå¯¹æ¯”å›¾
    print("ğŸ“ˆ Generating Benchmarks Comparison chart (Lite & Pro vs ETF & Star50 benchmark)...")
    if etf_data and lite_unrealized_pnl and pro_unrealized_pnl:
        plot_benchmarks_comparison(etf_data, lite_unrealized_pnl, pro_unrealized_pnl, star50_series)
    else:
        print("âš  Warning: Insufficient data for benchmarks comparison")

    # 4.7 ç”ŸæˆLiteå’ŒProçš„Realized benchmarkå¯¹æ¯”å›¾
    print("ğŸ“ˆ Generating Realized Benchmarks Comparison chart (Lite & Pro vs ETF & Star50 benchmark)...")
    if etf_data and lite_realized_pnl and pro_realized_pnl:
        plot_benchmarks_realized(etf_data, lite_realized_pnl, pro_realized_pnl, star50_series)
    else:
        print("âš  Warning: Insufficient data for realized benchmarks comparison")
    
    # 5. ç”Ÿæˆç»Ÿè®¡æ‘˜è¦ï¼ˆä½¿ç”¨å½“å‰é€‰å®šç‰ˆæœ¬çš„Realized PnLï¼‰
    print("\nğŸ“Š Generating summary statistics...")
    if not realized_pnl_data:
        print("âš  Warning: No PnL data available for summary statistics.")
    else:
        summary = generate_summary_stats(realized_pnl_data)
        summary_file = OUTPUT_DIR / "performance_summary.md"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary)
        print(f"âœ“ Saved: {summary_file}")
    
    print(f"\n" + "=" * 60)
    print("âœ… All visualizations generated successfully!")
    print(f"ğŸ“Š Generated charts (16 total):")
    print(f"   â€¢ pnl_weekly_unrealized_lite.png (Lite Unrealized)")
    print(f"   â€¢ pnl_weekly_realized_lite.png (Lite Realized)")
    print(f"   â€¢ pnl_weekly_unrealized_pro.png (Pro Unrealized)")
    print(f"   â€¢ pnl_weekly_realized_pro.png (Pro Realized)")
    print(f"   â€¢ etf_performance.png")
    print(f"   â€¢ etf_vs_models_comparison.png")
    print(f"   â€¢ benchmarks_lite_vs_pro.png (Lite & Pro vs Benchmarks)")
    print(f"   â€¢ benchmarks_lite_vs_pro_realized.png (Lite & Pro vs Benchmarks, Realized)")
    print(f"   â€¢ model_version_comparison.png")
    print(f"   â€¢ stock_attention.png (All Models)")
    print(f"   â€¢ stock_attention_lite.png (Lite Models)")
    print(f"   â€¢ stock_attention_pro.png (Pro Models)")
    print(f"   â€¢ model_attention_by_date_lite.png (Lite Models)")
    print(f"   â€¢ model_attention_by_date_pro.png (Pro Models)")
    print(f"   â€¢ performance_summary.md")
    print(f"ğŸ“ Output directory: {OUTPUT_DIR.absolute()}")
    print(f"ğŸ“Œ Active model version for other benchmarks: {MODEL_VERSION.upper()}")
    print("=" * 60)




if __name__ == "__main__":
    main()
