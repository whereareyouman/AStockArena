# -*- coding: utf-8 -*-
"""é«˜æ€§èƒ½äº¤æ˜“ API æœåŠ¡å™¨

æ¶æ„è®¾è®¡ï¼šè¯»å†™åˆ†ç¦»ä¸åå°åŒæ­¥ (CQRS-lite)
- å†…å­˜çŠ¶æ€æº (Single Source of Truth)ï¼šGlobalState å•ä¾‹
- åŒè·¯åå°å·¥äººï¼šMarketWorker + PortfolioWorker
- éé˜»å¡æ¶æ„ï¼šAPI æ¥å£æ°¸è¿œç§’å›ç¼“å­˜æ•°æ® (Stale-While-Revalidate)
"""

import asyncio
import json
import logging
import os
import subprocess
import sys
import time
import uuid
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Set

from fastapi import BackgroundTasks, FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage
from agent_engine.agent.agent import AgenticWorkflow as BaseAgent

# --- é…ç½®ä¸å¸¸é‡ ---
LOG_DIR = Path(__file__).parent / "logs" / "jobs"
LOG_DIR.mkdir(parents=True, exist_ok=True)
DATA_DIR = Path(__file__).parent / "data_flow"
CONFIG_DIR = Path(__file__).parent / "settings"
DEFAULT_CONFIG = CONFIG_DIR / "default_config.json"
RUNTIME_ENV = Path(__file__).parent / "runtime_env.json"
DATA_FILE = DATA_DIR / "ai_stock_data.json"

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("API")


# =============================================================================
# å…¨å±€å†…å­˜çŠ¶æ€ (The In-Memory State) - æ ¸å¿ƒä¼˜åŒ–
# =============================================================================
class GlobalState:
    """
    å…¨å±€å†…å­˜çŠ¶æ€å®¹å™¨ã€‚
    æ‰€æœ‰ API è¯»å–è¯·æ±‚ç›´æ¥ä»è¿™é‡Œè·å–æ•°æ®ï¼Œä¸å†è¿›è¡Œ IO æ“ä½œã€‚
    """
    def __init__(self):
        # è¡Œæƒ…æ•°æ®
        self.market_quotes: Dict[str, Dict[str, Any]] = {}  # ç¬¦å· -> è¡Œæƒ…å¿«ç…§
        self.monitored_symbols: Set[str] = set()            # éœ€è¦æ‹‰å–è¡Œæƒ…çš„è‚¡ç¥¨æ± 
        
        # æŒä»“ä¸ç»Ÿè®¡
        self.portfolios: Dict[str, Dict[str, Any]] = {}     # æ¨¡å‹ç­¾å -> èµ„äº§æ¦‚å†µ
        self.model_stats: Dict[str, Dict[str, Any]] = {}    # æ¨¡å‹ç­¾å -> å®Œæ•´ç»Ÿè®¡
        self.position_records: Dict[str, List[Dict]] = {}   # ç­¾å -> å†å²è®°å½•ç¼“å­˜
        self.position_mtimes: Dict[str, float] = {}         # æ–‡ä»¶ä¿®æ”¹æ—¶é—´è¿½è¸ª
        
        # å¤§æ–‡ä»¶ç¼“å­˜
        self.stock_history_cache: Dict[str, Any] = {}       # ai_stock_data.json ç¼“å­˜
        self.stock_history_mtime: float = 0
        
        # ä»»åŠ¡ç®¡ç†
        self.jobs: Dict[str, Dict[str, Any]] = {}
        
        # ç³»ç»ŸçŠ¶æ€
        self.system_status: Dict[str, Any] = {
            "initialized": False,
            "market_worker_running": False,
            "portfolio_worker_running": False,
            "last_market_update": None,
            "last_portfolio_update": None,
        }
        
        # ç³»ç»Ÿé…ç½®ï¼ˆä» default_config.json åŠ è½½ï¼‰
        self.system_config: Dict[str, Any] = {}
        
        # é”
        self._quote_lock = asyncio.Lock()
        self._portfolio_lock = asyncio.Lock()

    def update_quote(self, symbol: str, data: Dict[str, Any]):
        self.market_quotes[symbol] = data

    def get_quote(self, symbol: str) -> Optional[Dict[str, Any]]:
        return self.market_quotes.get(symbol)

    def update_portfolio(self, signature: str, data: Dict[str, Any]):
        self.portfolios[signature] = data

    def get_portfolio(self, signature: str) -> Optional[Dict[str, Any]]:
        return self.portfolios.get(signature)

    def update_model_stats(self, signature: str, data: Dict[str, Any]):
        self.model_stats[signature] = data

    def get_model_stats(self, signature: str) -> Optional[Dict[str, Any]]:
        return self.model_stats.get(signature)


# å…¨å±€å•ä¾‹
APP_STATE = GlobalState()


# =============================================================================
# è¾…åŠ©å‡½æ•°
# =============================================================================
def _truthy_env(name: str) -> bool:
    return os.getenv(name, "false").lower() in ("1", "true", "yes")


def _normalize_code(c: str) -> str:
    c = (c or "").strip().upper()
    if len(c) == 6 and c.isdigit():
        if c.startswith(("688", "689", "600", "601", "603", "605", "730", "735")):
            return f"SH{c}"
        if c.startswith(("000", "001", "002", "003", "300", "301", "302")):
            return f"SZ{c}"
    return c


def _symbol_candidates(symbol: str) -> List[str]:
    norm = (symbol or "").upper()
    plain = norm
    if norm.startswith(("SH", "SZ")) and len(norm) > 2:
        plain = norm[2:]
    candidates = {norm, plain, f"SH{plain}", f"SZ{plain}"}
    return [c for c in candidates if c]


def _load_config_dict(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise HTTPException(status_code=404, detail=f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        raise HTTPException(status_code=500, detail=f"é…ç½®æ–‡ä»¶è§£æå¤±è´¥: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")


def _load_config_dict_safe(path: Path) -> Dict[str, Any]:
    """ä¸æŠ›å¼‚å¸¸çš„ç‰ˆæœ¬ï¼Œç”¨äºåå° worker"""
    try:
        if path.exists():
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {}


def _get_enabled_signatures(config_path: Optional[Path] = None) -> List[str]:
    path = config_path or DEFAULT_CONFIG
    cfg = _load_config_dict_safe(path)
    return [
        m["signature"]
        for m in cfg.get("models", [])
        if m.get("enabled", True) and m.get("signature")
    ]


def _get_tsl_credentials() -> tuple:
    user = os.getenv("TSL_USERNAME") or os.getenv("TSL_USER")
    pwd = os.getenv("TSL_PASSWORD") or os.getenv("TSL_PASS")
    server = os.getenv("TSL_SERVER", "tsl.tinysoft.com.cn")
    try:
        port = int(os.getenv("TSL_PORT", "443"))
    except Exception:
        port = 443
    return user, pwd, server, port


def _load_runtime_signature() -> str | None:
    try:
        if RUNTIME_ENV.exists():
            with open(RUNTIME_ENV, "r", encoding="utf-8") as f:
                rt = json.load(f)
            return rt.get("SIGNATURE")
    except Exception:
        return None
    return None


def _position_file_for_signature(signature: str | None) -> Path:
    sig = signature or _load_runtime_signature()
    if not sig:
        raise HTTPException(status_code=400, detail="No signature provided and runtime_env SIGNATURE missing")
    return DATA_DIR / "trading_summary_each_agent" / sig / "position" / "position.jsonl"


def _load_initial_cash() -> float:
    """Load initial_cash from settings/default_config.json (fallback to 1000000)."""
    try:
        if DEFAULT_CONFIG.exists():
            with open(DEFAULT_CONFIG, "r", encoding="utf-8") as f:
                cfg = json.load(f)
            agent_cfg = (cfg or {}).get("agent_config", {})
            return float(agent_cfg.get("initial_cash", 1000000.0))
    except Exception:
        pass
    return 1000000.0


def _read_jsonl_tail(path: Path, limit: int = 100) -> list[dict]:
    """é«˜æ•ˆè¯»å– JSONL æ–‡ä»¶å°¾éƒ¨"""
    if not path.exists():
        return []
    lines: list[dict] = []
    try:
        with open(path, "rb") as f:
            try:
                # å¿«é€Ÿå®šä½åˆ°æ–‡ä»¶å°¾éƒ¨
                f.seek(0, os.SEEK_END)
                size = f.tell()
                # è¯»å–æœ€åçº¦ 256KBï¼ˆè¶³ä»¥è¦†ç›–å¤§å¤šæ•° limitï¼‰
                seek_pos = max(0, size - 256 * 1024)
                f.seek(seek_pos)
                content = f.read().decode("utf-8", errors="ignore")
            except OSError:
                f.seek(0)
                content = f.read().decode("utf-8", errors="ignore")

        for line in content.strip().split("\n"):
            line = line.strip()
            if not line:
                continue
            try:
                lines.append(json.loads(line))
            except Exception:
                continue
        return lines[-limit:]
    except Exception:
        return []


def _sanitize_provider_detail(detail: str) -> str:
    lowered = detail.lower()
    if "429" in detail or "too many request" in lowered or "rate limit" in lowered:
        return "ä¸Šæ¸¸æ•°æ®æºæš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚"
    if "login failed" in lowered or "missing" in lowered:
        return "æ— æ³•è¿æ¥è‡³è¡Œæƒ…æ•°æ®æä¾›æ–¹ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    return detail


# =============================================================================
# åå°å·¥äºº (Background Workers) - çº¯æœ¬åœ°æ•°æ®æ¨¡å¼
# =============================================================================

# æ•°æ®æ¨¡å¼é…ç½®
# USE_LOCAL_DATA_ONLY=true: å®Œå…¨ä½¿ç”¨æœ¬åœ° ai_stock_data.jsonï¼Œé€‚åˆå›æµ‹/æ¼”ç¤º
# USE_LOCAL_DATA_ONLY=false: å°è¯•è¿æ¥ TinySoftï¼Œå¤±è´¥åˆ™é™çº§åˆ°æœ¬åœ°
USE_LOCAL_DATA_ONLY = os.getenv("USE_LOCAL_DATA_ONLY", "true").lower() in ("1", "true", "yes")


def _find_price_at_time(
    data_list: List[Dict[str, Any]],
    target_datetime: Optional[str],
    target_date: Optional[str],
) -> tuple[float, float, str, str]:
    """
    åœ¨å†å²æ•°æ®åˆ—è¡¨ä¸­æŸ¥æ‰¾æœ€æ¥è¿‘ç›®æ ‡æ—¶é—´çš„ä»·æ ¼ã€‚
    
    ç­–ç•¥ï¼š
    1. å¦‚æœæœ‰ target_datetime (å¦‚ "2025-09-19 14:00:00")ï¼Œç²¾ç¡®åŒ¹é…æˆ–æ‰¾æœ€è¿‘çš„ <= è®°å½•
    2. å¦‚æœåªæœ‰ target_date (å¦‚ "2025-09-19")ï¼Œæ‰¾è¯¥æ—¥æœŸå†…æœ€åä¸€æ¡è®°å½•
    3. å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›åˆ—è¡¨æœ€åä¸€æ¡
    
    Returns: (price, volume, data_time, source_type)
    """
    if not data_list:
        return 0.0, 0.0, "", "empty"
    
    # æ— ç›®æ ‡æ—¶é—´ï¼Œè¿”å›æœ€åä¸€æ¡
    if not target_datetime and not target_date:
        last = data_list[-1]
        price = float(last.get("buy1") or last.get("close") or 0)
        volume = float(last.get("vol") or 0)
        data_time = last.get("date") or last.get("time") or ""
        return price, volume, data_time, "latest"
    
    # æœ‰ç›®æ ‡æ—¶é—´ï¼Œè¿›è¡ŒåŒ¹é…
    search_key = target_datetime or target_date
    best_match = None
    
    # å€’åºéå†ï¼Œæ‰¾ç¬¬ä¸€ä¸ª <= search_key çš„è®°å½•
    for item in reversed(data_list):
        item_time = item.get("date") or item.get("time") or ""
        
        # å¯¹äºå°æ—¶çº¿ï¼Œæ ¼å¼æ˜¯ "2025-09-19 14:00:00"
        # å¯¹äºæ—¥çº¿ï¼Œæ ¼å¼æ˜¯ "2025-09-19"
        
        if target_datetime:
            # ç²¾ç¡®æ—¶é—´åŒ¹é…ï¼ˆå°æ—¶çº¿ï¼‰
            if item_time <= target_datetime:
                best_match = item
                break
        elif target_date:
            # æ—¥æœŸåŒ¹é…
            item_date = item_time[:10] if len(item_time) >= 10 else item_time
            if item_date <= target_date:
                best_match = item
                break
    
    if best_match:
        price = float(best_match.get("buy1") or best_match.get("close") or 0)
        volume = float(best_match.get("vol") or 0)
        data_time = best_match.get("date") or best_match.get("time") or ""
        return price, volume, data_time, f"synced@{search_key}"
    
    # æ‰¾ä¸åˆ°æ›´æ—©çš„è®°å½•ï¼Œç”¨ç¬¬ä¸€æ¡
    first = data_list[0]
    price = float(first.get("buy1") or first.get("close") or 0)
    volume = float(first.get("vol") or 0)
    data_time = first.get("date") or first.get("time") or ""
    return price, volume, data_time, "earliest"


def _get_current_simulation_time() -> tuple[Optional[str], Optional[str]]:
    """
    ä»æ‰€æœ‰æ¨¡å‹çš„æŒä»“è®°å½•ä¸­ï¼Œè·å–å½“å‰ç³»ç»Ÿçš„"æ¨¡æ‹Ÿæ—¶é—´"ã€‚
    
    Returns: (decision_time, date)
        - decision_time: å¦‚ "2025-09-19 14:00:00" (å°æ—¶çº§ç²¾åº¦)
        - date: å¦‚ "2025-09-19" (æ—¥çº§ç²¾åº¦)
    """
    latest_datetime = None
    latest_date = None
    
    # éå†æ‰€æœ‰æ¨¡å‹ï¼Œæ‰¾æœ€æ–°çš„æ—¶é—´æˆ³
    for sig, portfolio in APP_STATE.portfolios.items():
        dt = portfolio.get("decision_time")
        d = portfolio.get("date")
        
        if dt and (latest_datetime is None or dt > latest_datetime):
            latest_datetime = dt
        if d and (latest_date is None or d > latest_date):
            latest_date = d
    
    # ä¹Ÿæ£€æŸ¥ position_records ä¸­çš„åŸå§‹è®°å½•
    for sig, records in APP_STATE.position_records.items():
        if records:
            last = records[-1]
            dt = last.get("decision_time")
            d = last.get("date")
            if dt and (latest_datetime is None or dt > latest_datetime):
                latest_datetime = dt
            if d and (latest_date is None or d > latest_date):
                latest_date = d
    
    return latest_datetime, latest_date


async def market_data_worker():
    """
    è¡Œæƒ…åŒæ­¥ Worker - æ”¯æŒåŒæ¨¡å¼åˆ‡æ¢
    
    æ¨¡å¼ 1 (USE_LOCAL_DATA_ONLY=trueï¼Œé»˜è®¤):
        - å®Œå…¨ä½¿ç”¨æœ¬åœ° ai_stock_data.json
        - æ ¹æ® position.jsonl çš„æ—¶é—´æˆ³åŒæ­¥ä»·æ ¼
        - é€‚åˆå›æµ‹/æ¼”ç¤ºï¼Œé¿å…æ—¶é—´ç©¿è¶Š
    
    æ¨¡å¼ 2 (USE_LOCAL_DATA_ONLY=false):
        - ä¼˜å…ˆå°è¯• TinySoft å®æ—¶è¡Œæƒ…
        - å¤±è´¥åˆ™é™çº§åˆ°æœ¬åœ°ç¼“å­˜
        - é€‚åˆå®ç›˜ç›‘æ§
    """
    mode_name = "çº¯æœ¬åœ°æ¨¡å¼" if USE_LOCAL_DATA_ONLY else "æ··åˆæ¨¡å¼(TinySoftä¼˜å…ˆ)"
    logger.info(f"ğŸš€ å¯åŠ¨è¡Œæƒ…åŒæ­¥ä»»åŠ¡ ({mode_name})...")
    APP_STATE.system_status["market_worker_running"] = True
    APP_STATE.system_status["data_mode"] = "local-only" if USE_LOCAL_DATA_ONLY else "hybrid"

    # æ··åˆæ¨¡å¼ï¼šå»¶è¿ŸåŠ è½½ pyTSL
    ts = None
    client = None
    logged_in = False
    
    if not USE_LOCAL_DATA_ONLY:
        try:
            import pyTSL
            ts = pyTSL
            logger.info("âœ… pyTSL å·²åŠ è½½ï¼Œå°†å°è¯•è·å–å®æ—¶è¡Œæƒ…")
        except ImportError:
            logger.warning("âš ï¸ æœªæ‰¾åˆ° pyTSLï¼Œå°†ä½¿ç”¨æœ¬åœ°ç¼“å­˜æ¨¡å¼")

    while True:
        try:
            # 1. è·å–å½“å‰ç³»ç»Ÿçš„"æ¨¡æ‹Ÿæ—¶é—´"ï¼ˆæœ¬åœ°æ¨¡å¼ä½¿ç”¨ï¼‰
            sim_datetime, sim_date = _get_current_simulation_time()
            
            # 2. ç¡®å®šéœ€è¦æ›´æ–°çš„è‚¡ç¥¨åˆ—è¡¨
            symbols = list(APP_STATE.monitored_symbols)
            if not symbols:
                symbols = list(APP_STATE.stock_history_cache.keys())[:50]
                cfg = _load_config_dict_safe(DEFAULT_CONFIG)
                for model in cfg.get("models", []):
                    if model.get("enabled", True):
                        for s in model.get("stock_symbols", []):
                            norm = _normalize_code(s)
                            if norm not in symbols:
                                symbols.append(norm)

            if not symbols:
                await asyncio.sleep(2)
                continue

            quotes_batch: Dict[str, Dict[str, Any]] = {}
            data_source = "local"

            # ========== æ¨¡å¼ 2: æ··åˆæ¨¡å¼ - å°è¯• TinySoft ==========
            if not USE_LOCAL_DATA_ONLY and ts:
                user, pwd, server, port = _get_tsl_credentials()
                if user and pwd:
                    try:
                        # ç™»å½•
                        if client is None or not logged_in:
                            client = ts.Client(user, pwd, server, port)
                            login_res = client.login()
                            logged_in = (login_res == 1)
                            if logged_in:
                                logger.info("âœ… TinySoft è¿æ¥æˆåŠŸ")
                            else:
                                logger.warning("âš ï¸ TinySoft ç™»å½•å¤±è´¥ï¼Œé™çº§åˆ°æœ¬åœ°æ¨¡å¼")

                        # æ‰¹é‡è·å–å®æ—¶è¡Œæƒ…
                        if logged_in:
                            now = datetime.now()
                            begin_time = now - timedelta(days=1)
                            
                            for code in symbols:
                                try:
                                    r = client.query(
                                        stock=code,
                                        begin_time=begin_time,
                                        end_time=now,
                                        cycle='60åˆ†é’Ÿçº¿',
                                        fields='date, close, vol, amount, buy1'
                                    )
                                    if r.error() == 0:
                                        df = r.dataframe()
                                        if not df.empty:
                                            last = df.iloc[-1]
                                            price = float(last.get('buy1') or last.get('close') or 0)
                                            volume = float(last.get('vol') or 0)
                                            amount = float(last.get('amount') or 0)
                                            
                                            # è®¡ç®—æ¶¨è·Œå¹…
                                            change_pct = 0.0
                                            if len(df) >= 2:
                                                prev_close = float(df.iloc[-2].get('close') or 0)
                                                if prev_close > 0:
                                                    change_pct = (price / prev_close - 1) * 100
                                            
                                            quotes_batch[code] = {
                                                "code": code,
                                                "price": round(price, 4),
                                                "volume": volume,
                                                "turnover": round(amount / 1e8, 4),
                                                "changePercent": round(change_pct, 2),
                                                "ts": datetime.utcnow().isoformat() + "Z",
                                                "source": "tinysoft",
                                            }
                                            data_source = "tinysoft"
                                except Exception as e:
                                    logger.debug(f"æŸ¥è¯¢ {code} å¤±è´¥: {e}")
                    except Exception as e:
                        logger.warning(f"TinySoft è¿æ¥å¼‚å¸¸: {e}")
                        logged_in = False
                        client = None

            # ========== æœ¬åœ°æ•°æ®å¤„ç†ï¼ˆçº¯æœ¬åœ°æ¨¡å¼ æˆ– TinySoft æœªè·å–åˆ°çš„è‚¡ç¥¨ï¼‰==========
            sync_mode = "latest" if not sim_datetime and not sim_date else f"synced@{sim_datetime or sim_date}"

            for code in symbols:
                # å¦‚æœå·²ç»ä» TinySoft è·å–åˆ°äº†ï¼Œè·³è¿‡
                if code in quotes_batch:
                    continue

                # å°è¯•å¤šç§ä»£ç æ ¼å¼åŒ¹é…
                stock_data = None
                for cand in _symbol_candidates(code):
                    stock_data = APP_STATE.stock_history_cache.get(cand)
                    if stock_data:
                        break

                price, volume, data_time, source = 0.0, 0.0, "", "not-found"
                change_pct = 0.0

                if stock_data:
                    hourly = stock_data.get("å°æ—¶çº¿è¡Œæƒ…") or []
                    daily = stock_data.get("æ—¥çº¿è¡Œæƒ…") or []

                    # æœ¬åœ°æ¨¡å¼ï¼šæ ¹æ®æ¨¡æ‹Ÿæ—¶é—´æŸ¥æ‰¾
                    # æ··åˆæ¨¡å¼ï¼šç›´æ¥å–æœ€æ–°æ•°æ®
                    if USE_LOCAL_DATA_ONLY:
                        # çº¯æœ¬åœ°æ¨¡å¼ï¼šç²¾ç¡®æ—¶é—´åŒæ­¥
                        if hourly:
                            price, volume, data_time, source = _find_price_at_time(
                                hourly, sim_datetime, sim_date
                            )
                            source = f"hourly:{source}"
                        elif daily:
                            price, volume, data_time, source = _find_price_at_time(
                                daily, None, sim_date
                            )
                            source = f"daily:{source}"
                    else:
                        # æ··åˆæ¨¡å¼ï¼šå–æœ€æ–°æ•°æ®ä½œä¸ºå…œåº•
                        if hourly:
                            last = hourly[-1]
                            price = float(last.get("buy1") or last.get("close") or 0)
                            volume = float(last.get("vol") or 0)
                            data_time = last.get("date") or ""
                            source = "local-fallback:hourly"
                        elif daily:
                            last = daily[-1]
                            price = float(last.get("close") or 0)
                            volume = float(last.get("vol") or 0)
                            data_time = last.get("date") or ""
                            source = "local-fallback:daily"

                    # è®¡ç®—æ¶¨è·Œå¹…
                    target_list = hourly if hourly else daily
                    if len(target_list) >= 2 and data_time:
                        for i, item in enumerate(target_list):
                            if (item.get("date") or "") == data_time and i > 0:
                                prev_close = float(target_list[i-1].get("close") or 0)
                                if prev_close > 0:
                                    change_pct = (price / prev_close - 1) * 100
                                break

                quotes_batch[code] = {
                    "code": code,
                    "price": round(price, 4),
                    "volume": volume,
                    "changePercent": round(change_pct, 2),
                    "ts": data_time if USE_LOCAL_DATA_ONLY else datetime.utcnow().isoformat() + "Z",
                    "source": source,
                    "sim_time": sim_datetime or sim_date if USE_LOCAL_DATA_ONLY else None,
                }

            # 4. æ‰¹é‡æ›´æ–°å…¨å±€çŠ¶æ€
            for code, data in quotes_batch.items():
                APP_STATE.update_quote(code, data)

            APP_STATE.system_status["last_market_update"] = datetime.utcnow().isoformat()
            APP_STATE.system_status["sim_datetime"] = sim_datetime if USE_LOCAL_DATA_ONLY else None
            APP_STATE.system_status["sim_date"] = sim_date if USE_LOCAL_DATA_ONLY else None
            APP_STATE.system_status["sync_mode"] = sync_mode if USE_LOCAL_DATA_ONLY else data_source
            
            logger.debug(f"ğŸ“Š è¡Œæƒ…åŒæ­¥å®Œæˆ: {len(quotes_batch)} åª, æ¨¡å¼: {data_source}")

        except Exception as e:
            logger.error(f"âŒ è¡Œæƒ…åŒæ­¥å¤±è´¥: {e}")

        # æœ¬åœ°æ¨¡å¼æ¯ç§’åˆ·æ–°ï¼Œæ··åˆæ¨¡å¼æ¯3ç§’ï¼ˆå‡å°‘ç½‘ç»œè¯·æ±‚ï¼‰
        await asyncio.sleep(1 if USE_LOCAL_DATA_ONLY else 3)


async def portfolio_watcher_worker():
    """
    åå°ä»»åŠ¡ï¼šç›‘è§† position.jsonl æ–‡ä»¶ï¼Œè®¡ç®— PnL å¹¶æ›´æ–°å†…å­˜çŠ¶æ€ã€‚
    æ¯ç§’æ£€æŸ¥ä¸€æ¬¡æ–‡ä»¶å˜åŒ–ã€‚
    """
    logger.info("ğŸš€ å¯åŠ¨æŒä»“ç›‘æ§åå°ä»»åŠ¡...")
    APP_STATE.system_status["portfolio_worker_running"] = True

    initial_cash = _load_initial_cash()

    while True:
        try:
            signatures = _get_enabled_signatures()
            all_held_symbols: Set[str] = set()

            for sig in signatures:
                pos_file = _position_file_for_signature(sig)
                if not pos_file.exists():
                    continue

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ›´æ–°
                try:
                    mtime = pos_file.stat().st_mtime
                except Exception:
                    continue

                # å³ä½¿æ–‡ä»¶æœªå˜åŒ–ï¼Œä¹Ÿè¦é‡æ–°è®¡ç®— PnLï¼ˆå› ä¸ºè¡Œæƒ…å¯èƒ½å˜äº†ï¼‰
                file_changed = (mtime != APP_STATE.position_mtimes.get(sig))
                
                if file_changed:
                    APP_STATE.position_mtimes[sig] = mtime
                    # é‡æ–°è¯»å–æ–‡ä»¶
                    records = _read_jsonl_tail(pos_file, limit=2000)
                    APP_STATE.position_records[sig] = records
                else:
                    records = APP_STATE.position_records.get(sig, [])

                if not records:
                    continue

                latest = records[-1]
                positions = latest.get("positions", {}) or {}

                # è®¡ç®—èµ„äº§è¯¦æƒ…
                cash = float(positions.get("CASH", 0) or 0)
                total_equity = cash
                holdings: List[Dict[str, Any]] = []

                for code, detail in positions.items():
                    if code == "CASH":
                        continue
                    if not isinstance(detail, dict):
                        continue
                    shares = detail.get("shares", 0) or 0
                    if shares <= 0:
                        continue

                    norm_code = _normalize_code(code)
                    all_held_symbols.add(norm_code)

                    # ä»å…¨å±€è¡Œæƒ…ç¼“å­˜å–ä»·æ ¼ï¼ˆæé€Ÿï¼ï¼‰
                    quote = APP_STATE.get_quote(norm_code) or {}
                    entry_price = float(detail.get("avg_price") or 0)
                    current_price = quote.get("price") or entry_price or 0

                    market_value = shares * float(current_price)
                    total_equity += market_value
                    cost_basis = shares * entry_price
                    pnl = market_value - cost_basis
                    pnl_percent = (pnl / cost_basis * 100) if cost_basis > 0 else 0

                    holdings.append({
                        "symbol": norm_code,
                        "shares": shares,
                        "entry_price": round(entry_price, 2),
                        "current_price": round(float(current_price), 2),
                        "market_value": round(market_value, 2),
                        "pnl": round(pnl, 2),
                        "pnl_percent": round(pnl_percent, 2),
                        "purchase_date": detail.get("purchase_date", ""),
                        "valuation_source": quote.get("source", "fallback"),
                    })

                # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
                total_return_pct = (total_equity / initial_cash - 1.0) * 100.0

                # è®¡ç®—æ—¥æ”¶ç›Šåºåˆ—å’Œ Sharpe
                by_date: Dict[str, Dict] = {}
                for rec in records:
                    d = rec.get("date")
                    if not d:
                        continue
                    prev = by_date.get(d)
                    if prev is None or (rec.get("id", -1) > prev.get("id", -1)):
                        by_date[d] = rec

                dates_sorted = sorted(by_date.keys())
                daily_returns = []
                equity_series = []

                for d in dates_sorted:
                    rec = by_date[d]
                    pos = rec.get("positions", {}) or {}
                    eq = float(pos.get("CASH", 0) or 0)
                    for c, det in pos.items():
                        if c == "CASH":
                            continue
                        if isinstance(det, dict):
                            sh = det.get("shares", 0) or 0
                            if sh > 0:
                                nc = _normalize_code(c)
                                q = APP_STATE.get_quote(nc) or {}
                                pr = q.get("price") or det.get("avg_price", 0)
                                eq += sh * float(pr)
                    equity_series.append(eq)

                for i in range(1, len(equity_series)):
                    if equity_series[i-1] > 0:
                        daily_returns.append((equity_series[i] / equity_series[i-1] - 1) * 100)

                # è®¡ç®— Sharpe (å¹´åŒ–)
                sharpe = 0.0
                if len(daily_returns) > 1:
                    import statistics
                    mean_ret = statistics.mean(daily_returns)
                    std_ret = statistics.stdev(daily_returns)
                    if std_ret > 0:
                        sharpe = (mean_ret * (252 ** 0.5)) / std_ret

                # è®¡ç®—æœ€å¤§å›æ’¤
                peak = initial_cash
                max_dd = 0.0
                for eq in equity_series:
                    if eq > peak:
                        peak = eq
                    dd = (eq / peak - 1.0) * 100.0 if peak > 0 else 0.0
                    if dd < max_dd:
                        max_dd = dd

                # äº¤æ˜“æ¬¡æ•°
                trade_count = sum(
                    1 for rec in records
                    if (rec.get("this_action") or {}).get("action") in {"buy", "sell"}
                )

                # æ›´æ–°å…¨å±€çŠ¶æ€
                portfolio_data = {
                    "signature": sig,
                    "date": latest.get("date"),
                    "decision_time": latest.get("decision_time"),
                    "total_equity": round(total_equity, 2),
                    "cash": round(cash, 2),
                    "holdings_count": len(holdings),
                    "holdings": holdings,
                    "updated_at": datetime.utcnow().isoformat(),
                }
                APP_STATE.update_portfolio(sig, portfolio_data)

                stats_data = {
                    "signature": sig,
                    "latest_date": latest.get("date"),
                    "total_return_pct": round(total_return_pct, 2),
                    "sharpe_ratio": round(sharpe, 2),
                    "max_drawdown_pct": round(max_dd, 2),
                    "position_count": len(holdings),
                    "cash": round(cash, 2),
                    "equity": round(total_equity, 2),
                    "last_action": latest.get("this_action"),
                    "total_records": len(records),
                    "trade_count": trade_count,
                    "holdings": holdings,
                    "valuation_source": "worker-computed",
                    "updated_at": datetime.utcnow().isoformat(),
                }
                APP_STATE.update_model_stats(sig, stats_data)

            # æ›´æ–°å…³æ³¨åˆ—è¡¨
            APP_STATE.monitored_symbols.update(all_held_symbols)
            APP_STATE.system_status["last_portfolio_update"] = datetime.utcnow().isoformat()

        except Exception as e:
            logger.error(f"âŒ æŒä»“ç›‘æ§å¤±è´¥: {e}")

        await asyncio.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡


async def stock_data_loader_worker():
    """
    åå°ä»»åŠ¡ï¼šæ‡’åŠ è½½/ç¼“å­˜å¤§çš„ ai_stock_data.json æ–‡ä»¶ã€‚
    ä»…åœ¨æ–‡ä»¶å˜åŒ–æ—¶é‡æ–°åŠ è½½ã€‚
    """
    logger.info("ğŸš€ å¯åŠ¨å†å²æ•°æ®åŠ è½½ä»»åŠ¡...")
    
    while True:
        try:
            if DATA_FILE.exists():
                mtime = DATA_FILE.stat().st_mtime
                if mtime != APP_STATE.stock_history_mtime:
                    logger.info("ğŸ“‚ é‡è½½ ai_stock_data.json ...")
                    start = time.time()
                    with open(DATA_FILE, "r", encoding="utf-8") as f:
                        APP_STATE.stock_history_cache = json.load(f)
                    APP_STATE.stock_history_mtime = mtime
                    elapsed = time.time() - start
                    logger.info(f"âœ… å†å²æ•°æ®åŠ è½½å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f}sï¼Œå…± {len(APP_STATE.stock_history_cache)} åªè‚¡ç¥¨")
        except Exception as e:
            logger.error(f"âŒ å†å²æ•°æ®åŠ è½½å¤±è´¥: {e}")

        await asyncio.sleep(10)  # æ¯ 10 ç§’æ£€æŸ¥ä¸€æ¬¡


# =============================================================================
# FastAPI ç”Ÿå‘½å‘¨æœŸ
# =============================================================================
@asynccontextmanager
async def lifespan(app: FastAPI):
    """å¯åŠ¨åå°ä»»åŠ¡"""
    logger.info("=" * 60)
    logger.info("ğŸ¯ é«˜æ€§èƒ½äº¤æ˜“ API å¯åŠ¨ä¸­...")
    logger.info("=" * 60)
    
    # é¢„åŠ è½½å†å²æ•°æ®
    if DATA_FILE.exists():
        try:
            with open(DATA_FILE, "r", encoding="utf-8") as f:
                APP_STATE.stock_history_cache = json.load(f)
            APP_STATE.stock_history_mtime = DATA_FILE.stat().st_mtime
            logger.info(f"âœ… é¢„åŠ è½½å®Œæˆ: {len(APP_STATE.stock_history_cache)} åªè‚¡ç¥¨")
        except Exception as e:
            logger.warning(f"âš ï¸ é¢„åŠ è½½å¤±è´¥: {e}")

    # åŠ è½½ç³»ç»Ÿé…ç½®
    try:
        config = _load_config_dict_safe(DEFAULT_CONFIG)
        if config:
            APP_STATE.system_config = config
            enabled_count = sum(1 for m in config.get("models", []) if m.get("enabled", True))
            logger.info(f"âœ… ç³»ç»Ÿé…ç½®åŠ è½½å®Œæˆï¼ˆ{enabled_count}/{len(config.get('models', []))} ä¸ªæ¨¡å‹å¯ç”¨ï¼‰")
        else:
            logger.warning("âš ï¸ æœªèƒ½åŠ è½½ç³»ç»Ÿé…ç½®")
    except Exception as e:
        logger.warning(f"âš ï¸ ç³»ç»Ÿé…ç½®åŠ è½½å¤±è´¥: {e}")

    # å¯åŠ¨åå°ä»»åŠ¡
    tasks = [
        asyncio.create_task(market_data_worker()),
        asyncio.create_task(portfolio_watcher_worker()),
        asyncio.create_task(stock_data_loader_worker()),
    ]
    
    APP_STATE.system_status["initialized"] = True
    logger.info("âœ… åå°ä»»åŠ¡å·²å¯åŠ¨")
    
    yield
    
    # æ¸…ç†
    for task in tasks:
        task.cancel()
    logger.info("ğŸ‘‹ API æœåŠ¡å·²å…³é—­")


app = FastAPI(
    title="é«˜æ€§èƒ½äº¤æ˜“ API",
    description="é‡‡ç”¨åå°åŒæ­¥æ¶æ„ï¼ŒAPI å“åº”å»¶è¿Ÿ < 1ms",
    version="2.0.0",
    lifespan=lifespan,
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# =============================================================================
# æé€Ÿ API æ¥å£ (Zero-IO in handler) - æ ¸å¿ƒä¼˜åŒ–
# =============================================================================
@app.get("/")
async def root_status():
    """è¿”å›ç³»ç»ŸçŠ¶æ€ï¼ŒåŒ…å«å½“å‰æ¨¡æ‹Ÿæ—¶é—´"""
    sim_datetime = APP_STATE.system_status.get("sim_datetime")
    sim_date = APP_STATE.system_status.get("sim_date")
    
    return {
        "status": "ok",
        "mode": "high-performance",
        "data_mode": APP_STATE.system_status.get("data_mode", "local-only"),
        "message": "AStockArena é«˜æ€§èƒ½åç«¯è¿è¡Œä¸­ (çº¯æœ¬åœ°æ•°æ®æ¨¡å¼)",
        
        # æ¨¡æ‹Ÿæ—¶é—´ä¿¡æ¯ï¼ˆå…³é”®ï¼ï¼‰
        "simulation": {
            "current_datetime": sim_datetime,
            "current_date": sim_date,
            "sync_mode": APP_STATE.system_status.get("sync_mode", "initializing"),
            "note": "API è¿”å›çš„ä»·æ ¼ä¸ Agent å†³ç­–æ—¶çœ‹åˆ°çš„ä»·æ ¼ä¸€è‡´" if sim_datetime or sim_date else "ç­‰å¾…äº¤æ˜“æ•°æ®...",
        },
        
        # ç¼“å­˜ç»Ÿè®¡
        "cache_stats": {
            "monitored_symbols": len(APP_STATE.monitored_symbols),
            "cached_quotes": len(APP_STATE.market_quotes),
            "cached_portfolios": len(APP_STATE.portfolios),
            "stock_history_count": len(APP_STATE.stock_history_cache),
        },
        
        "system_status": APP_STATE.system_status,
    }


@app.get("/api/market/quotes")
async def market_quotes(codes: str = Query(..., description="Comma separated codes")):
    """
    æé€Ÿè¡Œæƒ…æ¥å£ï¼šç›´æ¥è¿”å›å†…å­˜ç¼“å­˜ï¼Œå»¶è¿Ÿ < 1msã€‚
    åŒ…å« AI æŒä»“ç»Ÿè®¡ä¿¡æ¯ã€‚
    """
    code_list = [_normalize_code(c) for c in codes.split(",") if c.strip()]
    if not code_list:
        raise HTTPException(status_code=400, detail="codes query param is required")

    # å°†è¯·æ±‚çš„è‚¡ç¥¨åŠ å…¥å…³æ³¨åˆ—è¡¨
    APP_STATE.monitored_symbols.update(code_list)

    # é¢„è®¡ç®—æ¯åªè‚¡ç¥¨çš„ AI æŒä»“ç»Ÿè®¡
    ai_stats: Dict[str, Dict[str, Any]] = {}
    for code in code_list:
        ai_stats[code] = {"holding_count": 0, "trade_volume": 0, "attention_score": 0}

    # ç»Ÿè®¡ AI æŒä»“æ•°é‡ï¼ˆå½“å‰æŒä»“ï¼‰
    for sig, portfolio in APP_STATE.portfolios.items():
        for holding in portfolio.get("holdings", []):
            symbol = _normalize_code(holding.get("symbol", ""))
            if symbol in ai_stats:
                ai_stats[symbol]["holding_count"] += 1

    # è®¡ç®— AI å…³æ³¨åº¦ï¼ˆ30å¤©å†…ï¼Œæ¯æœ‰ä¸€å¤©æœ‰ä¸€ä¸ª AI æŒæœ‰è¯¥è‚¡å°± +1 åˆ†ï¼‰
    # ä»¥åŠ AI äº¤æ˜“é‡
    cutoff_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
    
    for sig, records in APP_STATE.position_records.items():
        # ç”¨äºè¿½è¸ªè¯¥æ¨¡å‹åœ¨æ¯å¤©æ˜¯å¦æŒæœ‰æŸåªè‚¡ç¥¨
        daily_holdings: Dict[str, Set[str]] = {}  # date -> set of symbols held
        
        for rec in records:
            rec_date = rec.get("date")
            if not rec_date or rec_date < cutoff_date:
                continue
            
            # æ£€æŸ¥è¯¥è®°å½•ä¸­æŒæœ‰å“ªäº›è‚¡ç¥¨
            positions = rec.get("positions", {}) or {}
            for code_key, detail in positions.items():
                if code_key == "CASH":
                    continue
                if isinstance(detail, dict) and (detail.get("shares") or 0) > 0:
                    norm_code = _normalize_code(code_key)
                    if norm_code in ai_stats:
                        if rec_date not in daily_holdings:
                            daily_holdings[rec_date] = set()
                        daily_holdings[rec_date].add(norm_code)
            
            # ç»Ÿè®¡äº¤æ˜“é‡
            action = rec.get("this_action") or {}
            symbol = _normalize_code(action.get("symbol", ""))
            if symbol in ai_stats and action.get("action") in ("buy", "sell"):
                ai_stats[symbol]["trade_volume"] += abs(action.get("amount") or 0)
        
        # ç´¯åŠ å…³æ³¨åº¦ï¼šæ¯å¤©æ¯ä¸ªæ¨¡å‹æŒæœ‰è¯¥è‚¡å°± +1
        for date, symbols in daily_holdings.items():
            for symbol in symbols:
                if symbol in ai_stats:
                    ai_stats[symbol]["attention_score"] += 1

    results = []
    source = "worker-cache"

    for code in code_list:
        # ç›´æ¥ä»å†…å­˜è·å–
        quote = APP_STATE.get_quote(code)

        if not quote:
            # å›é€€åˆ°å†å²ç¼“å­˜
            hist = APP_STATE.stock_history_cache.get(code)
            fallback_price = 0
            if hist:
                hourly = hist.get("å°æ—¶çº¿è¡Œæƒ…") or []
                if hourly:
                    fallback_price = float(hourly[-1].get("close") or 0)
                elif hist.get("æ—¥çº¿è¡Œæƒ…"):
                    daily = hist["æ—¥çº¿è¡Œæƒ…"]
                    if daily:
                        fallback_price = float(daily[-1].get("close") or 0)

            quote = {
                "code": code,
                "price": round(fallback_price, 4),
                "changePercent": 0,
                "volume": 0,
                "turnover": 0,
                "ts": datetime.utcnow().isoformat() + "Z",
                "source": "history-fallback",
            }
            source = "mixed"
        else:
            quote = dict(quote)

        # æ·»åŠ  AI ç»Ÿè®¡ä¿¡æ¯
        stats = ai_stats.get(code, {})
        quote["aiHoldingCount"] = stats.get("holding_count", 0)      # å½“å‰æŒä»“çš„ AI æ•°é‡
        quote["aiTradeVolume"] = stats.get("trade_volume", 0)        # 30å¤©å†… AI æ€»äº¤æ˜“é‡
        quote["aiAttentionScore"] = stats.get("attention_score", 0)  # 30å¤©å†… AI å…³æ³¨åº¦ï¼ˆæ¯å¤©æ¯æ¨¡å‹æŒæœ‰+1ï¼‰

        results.append(quote)

    return {"quotes": results, "source": source}


@app.get("/api/system/config")
async def get_system_config():
    """
    è¿”å›ç³»ç»Ÿé…ç½®ä¿¡æ¯ï¼ˆäº¤æ˜“è§„åˆ™ã€æ¨¡å‹é…ç½®ã€æ•°æ®æºçŠ¶æ€ç­‰ï¼‰
    """
    config = APP_STATE.system_config.copy() if APP_STATE.system_config else {}
    
    # ç»Ÿè®¡å¯ç”¨çš„æ¨¡å‹æ•°é‡
    enabled_models = [
        m for m in config.get("models", [])
        if m.get("enabled", True)
    ]
    model_count = len(enabled_models)
    
    # è·å–æ•°æ®æºçŠ¶æ€ï¼ˆä» system_status è·å–ï¼‰
    data_mode = APP_STATE.system_status.get("data_mode", "local-only")
    # æ ¹æ®æ•°æ®æ¨¡å¼åˆ¤æ–­è¿æ¥çŠ¶æ€
    if data_mode == "local-only":
        data_source_status = "connected"  # æœ¬åœ°æ•°æ®æ¨¡å¼æ€»æ˜¯è¿æ¥çŠ¶æ€
    elif data_mode in ["hybrid", "tinystock"]:
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡Œæƒ…æ•°æ®æ›´æ–°
        last_update = APP_STATE.system_status.get("last_market_update")
        data_source_status = "connected" if last_update else "disconnected"
    else:
        data_source_status = "unknown"
    
    # æ ¼å¼åŒ–é…ç½®ä¿¡æ¯
    trading_rules = config.get("trading_rules", {})
    risk_management = config.get("risk_management", {})
    agent_config = config.get("agent_config", {})
    data_config = config.get("data_config", {})
    
    return {
        "trading_rules": {
            "commission_rate": trading_rules.get("commission_rate", 0.0003),
            "commission_rate_percent": round(trading_rules.get("commission_rate", 0.0003) * 100, 4),
            "min_commission": trading_rules.get("min_commission", 5.0),
            "stamp_duty_rate": trading_rules.get("stamp_duty_rate", 0.0005),
            "stamp_duty_rate_percent": round(trading_rules.get("stamp_duty_rate", 0.0005) * 100, 4),
            "t_plus_one_enabled": True,  # T+1 æ˜¯ç¡¬ç¼–ç çš„äº¤æ˜“è§„åˆ™
        },
        "risk_management": {
            "single_stock_max_position": risk_management.get("single_stock_max_position", 0.50),
            "single_stock_max_position_percent": round(risk_management.get("single_stock_max_position", 0.50) * 100, 2),
        },
        "agent_config": {
            "initial_cash": agent_config.get("initial_cash", 1000000.0),
            "max_steps": agent_config.get("max_steps", 30),
            "max_retries": agent_config.get("max_retries", 3),
            "decision_frequency": "hourly",  # å†³ç­–é¢‘ç‡æ˜¯æ¯å°æ—¶
            "auto_trading_enabled": True,  # è‡ªåŠ¨äº¤æ˜“é»˜è®¤å¼€å¯
        },
        "models": {
            "total_count": len(config.get("models", [])),
            "enabled_count": model_count,
            "enabled_models": [
                {
                    "name": m.get("name"),
                    "signature": m.get("signature"),
                    "basemodel": m.get("basemodel"),
                }
                for m in enabled_models
            ],
        },
        "data_source": {
            "status": data_source_status,
            "mode": data_mode,
            "update_frequency": "realtime" if data_mode != "unknown" else "unknown",
        },
        "data_config": {
            "stock_json_path": data_config.get("stock_json_path", "./data_flow/ai_stock_data.json"),
            "news_csv_path": data_config.get("news_csv_path", "./data_flow/news.csv"),
            "history_days": 30,  # å†å²æ•°æ®å¤©æ•°ï¼ˆå¯ä»é…ç½®æˆ–å®é™…æ•°æ®è®¡ç®—ï¼‰
        },
    }


@app.get("/api/live/model-stats")
async def live_model_stats(signature: str | None = None):
    """
    æé€Ÿèµ„äº§ç»Ÿè®¡æ¥å£ï¼šç›´æ¥è¿”å› Worker è®¡ç®—å¥½çš„ç»“æœï¼Œå»¶è¿Ÿ < 1msã€‚
    """
    sig = signature or _load_runtime_signature()
    
    stats = APP_STATE.get_model_stats(sig)
    if stats:
        return stats

    # å¦‚æœè¿˜æ²¡å‡†å¤‡å¥½ï¼Œè¿”å›åˆå§‹åŒ–çŠ¶æ€
    return {
        "signature": sig,
        "equity": 0,
        "cash": 0,
        "total_return_pct": 0,
        "sharpe_ratio": 0,
        "max_drawdown_pct": 0,
        "position_count": 0,
        "trade_count": 0,
        "holdings": [],
        "status": "initializing",
        "note": "åå° worker æ­£åœ¨åˆå§‹åŒ–æ•°æ®ï¼Œè¯·ç¨å€™...",
    }


@app.get("/api/live/current-positions")
async def live_current_positions(signature: str | None = None):
    """
    æé€ŸæŒä»“æ¥å£ï¼šç›´æ¥ä»å†…å­˜è¯»å–ã€‚
    """
    sig = signature or _load_runtime_signature()
    
    portfolio = APP_STATE.get_portfolio(sig)
    if portfolio:
        return {
            "positions": portfolio.get("holdings", []),
            "cash": portfolio.get("cash", 0),
            "total_equity": portfolio.get("total_equity", 0),
            "date": portfolio.get("date"),
            "valuation_source": "worker-computed",
        }

    return {
        "positions": [],
        "cash": 0,
        "total_equity": 0,
        "date": None,
        "status": "initializing",
    }


@app.get("/api/live/position-lines")
async def live_position_lines(
    limit: int = Query(100, ge=1, le=2000),
    signature: str | None = None
):
    """è¿”å›æœ€è¿‘ N æ¡æŒä»“è®°å½•ï¼ˆç”¨äºå›¾è¡¨ï¼‰"""
    sig = signature or _load_runtime_signature()
    
    records = APP_STATE.position_records.get(sig, [])
    if not records:
        # å°è¯•ç›´æ¥è¯»å–
        try:
            pos_file = _position_file_for_signature(sig)
            records = _read_jsonl_tail(pos_file, limit)
        except Exception:
            pass

    out = []
    for it in records[-limit:]:
        positions = it.get("positions", {}) or {}
        cash = positions.get("CASH")
        cnt = sum(
            1 for k, v in positions.items()
            if k != "CASH" and isinstance(v, dict) and v.get("shares", 0) > 0
        )
        out.append({
            "date": it.get("date"),
            "id": it.get("id"),
            "cash": cash,
            "positions_count": cnt,
            "action": (it.get("this_action") or {}).get("action"),
            "symbol": (it.get("this_action") or {}).get("symbol"),
            "amount": (it.get("this_action") or {}).get("amount"),
        })
    return {"items": out}


@app.get("/api/live/latest-position")
async def live_latest_position(signature: str | None = None):
    """è¿”å›æœ€æ–°æŒä»“è®°å½•"""
    sig = signature or _load_runtime_signature()
    
    records = APP_STATE.position_records.get(sig, [])
    if records:
        return {"item": records[-1]}

    # å›é€€åˆ°æ–‡ä»¶è¯»å–
    try:
        pos_file = _position_file_for_signature(sig)
        items = _read_jsonl_tail(pos_file, limit=1)
        if items:
            return {"item": items[-1]}
    except Exception:
        pass

    return {"item": None}


@app.get("/api/live/pnl-series")
async def live_pnl_series(
    signature: str | None = None,
    days: int = Query(30, ge=1, le=365),
    valuation: str = Query("equity", description="cash or equity")
):
    """è¿”å›æ¯æ—¥ PnL åºåˆ—"""
    sig = signature or _load_runtime_signature()
    initial_cash = _load_initial_cash()
    
    records = APP_STATE.position_records.get(sig, [])
    if not records:
        try:
            pos_file = _position_file_for_signature(sig)
            records = _read_jsonl_tail(pos_file, limit=10000)
        except Exception:
            return {"items": [], "valuation_used": valuation}

    # æŒ‰æ—¥æœŸåˆ†ç»„
    by_date: Dict[str, Dict] = {}
    for it in records:
        d = it.get("date")
        if not d:
            continue
        prev = by_date.get(d)
        if prev is None or (it.get("id", -1) > prev.get("id", -1)):
            by_date[d] = it

    dates_sorted = sorted(by_date.keys())[-days:]
    out = []

    for d in dates_sorted:
        rec = by_date[d]
        positions = rec.get("positions", {}) or {}
        cash = float(positions.get("CASH", 0) or 0)

        if valuation.lower() != "equity":
            ret_pct = (cash / initial_cash - 1.0) * 100.0
            out.append({"date": d, "returnPct": round(ret_pct, 2), "cash": round(cash, 2)})
        else:
            equity = cash
            for code, det in positions.items():
                if code == "CASH":
                    continue
                if isinstance(det, dict):
                    shares = det.get("shares", 0) or 0
                    if shares > 0:
                        norm = _normalize_code(code)
                        q = APP_STATE.get_quote(norm) or {}
                        price = q.get("price") or det.get("avg_price", 0)
                        equity += shares * float(price)

            ret_pct = (equity / initial_cash - 1.0) * 100.0
            out.append({"date": d, "returnPct": round(ret_pct, 2), "equity": round(equity, 2)})

    return {"items": out, "valuation_used": valuation}


@app.get("/api/live/recent-decisions")
async def live_recent_decisions(
    signature: str | None = None,
    limit: int = Query(20, ge=1, le=100)
):
    """è·å–æœ€è¿‘äº¤æ˜“å†³ç­–"""
    sig = signature or _load_runtime_signature()
    
    records = APP_STATE.position_records.get(sig, [])
    if not records:
        try:
            pos_file = _position_file_for_signature(sig)
            records = _read_jsonl_tail(pos_file, limit * 2)
        except Exception:
            return {"decisions": []}

    decisions = []
    for it in reversed(records):
        action = it.get("this_action") or {}
        positions = it.get("positions", {}) or {}
        
        holdings = sum(
            1 for k, v in positions.items()
            if k != "CASH" and isinstance(v, dict) and v.get("shares", 0) > 0
        )

        decisions.append({
            "date": it.get("date"),
            "time": it.get("decision_time"),
            "count": it.get("decision_count"),
            "action": action.get("action"),
            "symbol": action.get("symbol"),
            "amount": action.get("amount"),
            "cash": float(positions.get("CASH", 0) or 0),
            "holdings": holdings,
            "id": it.get("id"),
        })

        if len(decisions) >= limit:
            break

    return {"decisions": decisions}


@app.get("/api/live/stock-detail")
async def live_stock_detail(
    symbol: str = Query(..., description="è‚¡ç¥¨ä»£ç "),
    history_limit: int = Query(60, ge=10, le=200),
    news_limit: int = Query(6, ge=1, le=20),
):
    """è‚¡ç¥¨è¯¦æƒ…æ¥å£ï¼ˆè¯»å–ç¼“å­˜ï¼‰"""
    if not symbol:
        raise HTTPException(status_code=400, detail="symbol ä¸èƒ½ä¸ºç©º")

    normalized = _normalize_code(symbol)
    
    # ä»ç¼“å­˜è·å–
    stock_payload = APP_STATE.stock_history_cache.get(normalized)
    if not stock_payload:
        for cand in _symbol_candidates(symbol):
            stock_payload = APP_STATE.stock_history_cache.get(cand)
            if stock_payload:
                break

    if not stock_payload:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ° {symbol} çš„æ•°æ®ç¼“å­˜")

    # æ„é€ å“åº”
    hourly_raw = stock_payload.get("å°æ—¶çº¿è¡Œæƒ…", []) or []
    hourly_window = hourly_raw[-history_limit:]
    hourly_series = [
        {
            "time": item.get("date"),
            "price": item.get("close"),
            "open": item.get("open"),
            "high": item.get("high"),
            "low": item.get("low"),
            "volume": item.get("vol"),
            "amount": item.get("amount"),
            "bid": item.get("buy1"),
        }
        for item in hourly_window
        if item.get("date")
    ]

    # æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    hourly_indicators_raw = stock_payload.get("å°æ—¶çº¿æŒ‡æ ‡", []) or []
    hourly_indicators_window = hourly_indicators_raw[-history_limit:]
    hourly_indicators = [
        {
            "time": item.get("Date") or item.get("date"),
            "close": item.get("CLOSE") or item.get("close"),
            "K": item.get("K"),
            "D": item.get("D"),
            "J": item.get("J"),
            "BOLL": item.get("BOLL"),
            "BOLL_upper": item.get("UPR"),
            "BOLL_lower": item.get("DWN"),
        }
        for item in hourly_indicators_window
        if item.get("Date") or item.get("date")
    ]

    # æ—¥çº¿è¡Œæƒ…
    daily_raw = stock_payload.get("æ—¥çº¿è¡Œæƒ…", []) or []
    daily_window = daily_raw[-history_limit:]
    daily_series = [
        {
            "time": item.get("date"),
            "price": item.get("close"),
            "open": item.get("open"),
            "high": item.get("high"),
            "low": item.get("low"),
            "volume": item.get("vol"),
            "amount": item.get("amount"),
        }
        for item in daily_window
        if item.get("date")
    ]

    # æ—¥çº¿æŒ‡æ ‡æ•°æ®
    daily_indicators_raw = stock_payload.get("æ—¥çº¿æŒ‡æ ‡", []) or []
    daily_indicators_window = daily_indicators_raw[-history_limit:]
    daily_indicators = [
        {
            "time": item.get("Date") or item.get("date"),
            "close": item.get("CLOSE") or item.get("close"),
            "K": item.get("K"),
            "D": item.get("D"),
            "J": item.get("J"),
            "BOLL": item.get("BOLL"),
            "BOLL_upper": item.get("UPR"),
            "BOLL_lower": item.get("DWN"),
        }
        for item in daily_indicators_window
        if item.get("Date") or item.get("date")
    ]

    # æœ€æ–°è¡Œæƒ…
    quote = APP_STATE.get_quote(normalized) or {}

    summary = {
        "symbol": normalized,
        "name": stock_payload.get("åç§°") or stock_payload.get("name"),
        "latest_time": hourly_window[-1].get("date") if hourly_window else None,
        "latest_price": quote.get("price") or (hourly_window[-1].get("close") if hourly_window else None),
        "change_percent": stock_payload.get("æ¶¨è·Œå¹…"),
        "turnover_rate": stock_payload.get("æ¢æ‰‹ç‡"),
        "volume": stock_payload.get("æˆäº¤é‡"),
    }

    # AI æŒä»“ç»Ÿè®¡
    ai_positions = []
    ai_trades = []
    for sig, portfolio in APP_STATE.portfolios.items():
        for holding in portfolio.get("holdings", []):
            if _normalize_code(holding.get("symbol", "")) == normalized:
                ai_positions.append({
                    "signature": sig,
                    **holding,
                })
                break

    # ä»è®°å½•ä¸­æå–äº¤æ˜“
    for sig, records in APP_STATE.position_records.items():
        for rec in reversed(records[-50:]):
            action = rec.get("this_action") or {}
            if _normalize_code(action.get("symbol", "")) == normalized:
                ai_trades.append({
                    "signature": sig,
                    "date": rec.get("date"),
                    "decision_time": rec.get("decision_time"),
                    "action": action.get("action"),
                    "amount": action.get("amount"),
                })
                if len(ai_trades) >= 20:
                    break

    return {
        "summary": summary,
        "hourly_prices": hourly_series,
        "hourly_indicators": hourly_indicators,
        "daily_prices": daily_series,
        "daily_indicators": daily_indicators,
        "ai_positions": ai_positions,
        "ai_trades": ai_trades[:20],
        "ai_summary": {
            "holding_count": len(ai_positions),
            "trade_volume": sum(abs(t.get("amount") or 0) for t in ai_trades),
            "holding_models": [p.get("signature") for p in ai_positions],
        },
    }


@app.get("/api/live/news")
async def live_latest_news(
    limit: int = Query(10, ge=1, le=50),
    symbols: str | None = None
):
    """è·å–æœ€æ–°æ–°é—»"""
    import pandas as pd

    news_path = DATA_DIR / "news.csv"
    if not news_path.exists():
        return {"news": [], "note": "No news data available"}

    try:
        df = None
        for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb18030']:
            try:
                df = pd.read_csv(news_path, encoding=encoding)
                break
            except Exception:
                continue

        if df is None or df.empty:
            return {"news": [], "note": "Failed to read news data"}

        if symbols:
            symbol_list = [s.strip().upper() for s in symbols.split(",") if s.strip()]
            if 'symbol' in df.columns:
                df = df[df['symbol'].str.upper().isin(symbol_list)]

        time_col = 'publish_time' if 'publish_time' in df.columns else 'search_time'
        if time_col in df.columns:
            df[time_col] = pd.to_datetime(df[time_col], errors='coerce')
            df = df.dropna(subset=[time_col])
            df = df.sort_values(by=time_col, ascending=False)

        df = df.head(limit)

        news_items = []
        for _, row in df.iterrows():
            news_items.append({
                "title": str(row.get('title', '')),
                "content": str(row.get('content', ''))[:200],
                "publish_time": str(row.get('publish_time', '')),
                "symbol": str(row.get('symbol', '')),
                "source": str(row.get('source', 'Unknown')),
                "url": str(row.get('url', '')),
            })

        return {"news": news_items}

    except Exception as e:
        logger.warning(f"âš ï¸ News endpoint error: {e}")
        return {"news": [], "error": "æ–°é—»æºæš‚æ—¶ä¸å¯ç”¨"}


# =============================================================================
# LLM ä¼šè¯ç®¡ç† (ä¿ç•™åŸæœ‰åŠŸèƒ½)
# =============================================================================
class LLMChatRequest(BaseModel):
    signature: str
    prompt: str
    config_path: Optional[str] = None
    reset: bool = False
    system_prompt: Optional[str] = None


class LLMSession:
    """LLM ä¼šè¯ç®¡ç†å™¨"""

    def __init__(self, *, agent: BaseAgent, system_prompt: str, config_path: Path):
        self.agent = agent
        self.system_prompt = system_prompt
        self.config_path = config_path
        self.history: List[BaseMessage] = [SystemMessage(content=system_prompt)]
        self.lock = asyncio.Lock()
        self.created_at = datetime.utcnow()

    def reset_history(self, *, system_prompt: Optional[str] = None) -> None:
        if system_prompt:
            self.system_prompt = system_prompt
        self.history = [SystemMessage(content=self.system_prompt)]


LLM_SESSIONS: Dict[str, LLMSession] = {}
_LLM_SESSION_LOCK: Optional[asyncio.Lock] = None


def _get_llm_session_lock() -> asyncio.Lock:
    global _LLM_SESSION_LOCK
    if _LLM_SESSION_LOCK is None:
        _LLM_SESSION_LOCK = asyncio.Lock()
    return _LLM_SESSION_LOCK


def _session_cache_key(signature: str, config_path: Path) -> str:
    return f"{signature}::{str(config_path.resolve())}"


def _resolve_config_path(config_path: Optional[str]) -> Path:
    if not config_path:
        return DEFAULT_CONFIG
    candidate = Path(config_path).expanduser()
    if not candidate.is_absolute():
        candidate = (Path(__file__).parent / candidate).resolve()
    return candidate


def _select_model_config(config: Dict[str, Any], signature: str) -> Dict[str, Any]:
    for item in config.get("models", []):
        if item.get("signature") == signature:
            if not item.get("enabled", True):
                raise HTTPException(status_code=400, detail=f"æ¨¡å‹ {signature} å·²è¢«ç¦ç”¨")
            return item
    raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ° signature={signature} çš„æ¨¡å‹é…ç½®")


def _default_llm_system_prompt(signature: str, basemodel: Optional[str]) -> str:
    suffix = f"ï¼ˆåº•åº§ï¼š{basemodel}ï¼‰" if basemodel else ""
    return (
        f"ä½ æ˜¯äº¤æ˜“ä»£ç† {signature}{suffix} çš„å¯¹è¯æ¥å£ï¼Œåªèƒ½ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œ"
        "å›ç­”æ—¶ä¿æŒç®€æ´ï¼Œé¿å…æ‰§è¡ŒçœŸå®äº¤æ˜“ï¼Œä»…åšç­–ç•¥åˆ†ææˆ–è§£é‡Šã€‚"
    )


async def _build_agent_for_signature(signature: str, config_path: Path) -> BaseAgent:
    config = _load_config_dict(config_path)
    agent_config = config.get("agent_config", {})
    data_config = config.get("data_config", {})
    log_config = config.get("log_config", {})
    trading_rules = config.get("trading_rules", {})
    risk_management = config.get("risk_management", {})
    date_range = config.get("date_range", {}) or {}
    init_date = date_range.get("init_date") or datetime.utcnow().strftime("%Y-%m-%d")

    model_cfg = _select_model_config(config, signature)
    basemodel = model_cfg.get("basemodel")
    if not basemodel:
        raise HTTPException(status_code=400, detail=f"æ¨¡å‹ {signature} ç¼ºå°‘ basemodel å­—æ®µ")

    stock_symbols = model_cfg.get("stock_symbols") or BaseAgent.DEFAULT_STOCK_SYMBOLS
    stock_json_path = data_config.get("stock_json_path", "./data_flow/ai_stock_data.json")
    news_csv_path = data_config.get("news_csv_path", "./data_flow/news.csv")
    macro_csv_path = data_config.get("macro_csv_path")
    log_path = log_config.get("log_path", "./data_flow/agent_data")

    agent = BaseAgent(
        signature=signature,
        basemodel=basemodel,
        stock_symbols=stock_symbols,
        stock_json_path=stock_json_path,
        news_csv_path=news_csv_path,
        macro_csv_path=macro_csv_path,
        log_path=log_path,
        max_steps=agent_config.get("max_steps", 10),
        max_retries=agent_config.get("max_retries", 3),
        base_delay=agent_config.get("base_delay", 0.5),
        openai_base_url=model_cfg.get("openai_base_url"),
        openai_api_key=model_cfg.get("openai_api_key"),
        google_api_key=model_cfg.get("google_api_key"),
        safety_settings=model_cfg.get("safety_settings"),
        initial_cash=agent_config.get("initial_cash", 1_000_000.0),
        init_date=init_date,
        trading_rules=trading_rules,
        risk_management=risk_management,
        force_replay=bool(model_cfg.get("force_replay", False)),
    )
    await agent.initialize()
    return agent


async def _get_or_create_llm_session(
    signature: str,
    config_path: Path,
    system_prompt_override: Optional[str] = None,
) -> LLMSession:
    cache_key = _session_cache_key(signature, config_path)
    session = LLM_SESSIONS.get(cache_key)
    if session:
        if system_prompt_override and system_prompt_override != session.system_prompt:
            session.reset_history(system_prompt=system_prompt_override)
        return session

    lock = _get_llm_session_lock()
    async with lock:
        session = LLM_SESSIONS.get(cache_key)
        if session:
            if system_prompt_override and system_prompt_override != session.system_prompt:
                session.reset_history(system_prompt=system_prompt_override)
            return session

        agent = await _build_agent_for_signature(signature, config_path)
        prompt = system_prompt_override or _default_llm_system_prompt(signature, agent.basemodel)
        session = LLMSession(agent=agent, system_prompt=prompt, config_path=config_path)
        LLM_SESSIONS[cache_key] = session
        return session


async def _invoke_llm_session(session: LLMSession, prompt: str) -> Dict[str, Any]:
    if not session.agent or not session.agent.model:
        raise HTTPException(status_code=500, detail="LLM æ¨¡å‹å°šæœªåˆå§‹åŒ–å®Œæˆ")

    user_msg = HumanMessage(content=prompt)
    history = session.history + [user_msg]
    try:
        response = await session.agent.model.ainvoke(history)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLM è°ƒç”¨å¤±è´¥: {e}")

    session.history.extend([user_msg, response])
    content = getattr(response, "content", None)
    if isinstance(content, list):
        text_parts = [part.get("text", "") for part in content if isinstance(part, dict)]
        content = "\n".join(filter(None, text_parts)) or str(content)
    elif content is None:
        content = str(response)

    return {
        "signature": session.agent.signature,
        "model": session.agent.basemodel,
        "response": content,
        "history_length": len(session.history),
        "usage": getattr(response, "usage_metadata", None),
        "created_at": session.created_at.isoformat() + "Z",
    }


@app.get("/api/llm/ping")
async def llm_ping(config_path: Optional[str] = None):
    """LLM å¥åº·æ£€æŸ¥"""
    resolved_path = _resolve_config_path(config_path)
    config = _load_config_dict(resolved_path)
    available = [
        m.get("signature")
        for m in config.get("models", [])
        if m.get("enabled", True) and m.get("signature")
    ]
    return {
        "status": "ok",
        "session_count": len(LLM_SESSIONS),
        "available_signatures": available,
        "config_path": str(resolved_path),
    }


@app.post("/api/llm/ask")
async def llm_ask(payload: LLMChatRequest):
    """LLM å¯¹è¯æ¥å£"""
    prompt = (payload.prompt or "").strip()
    if not prompt:
        raise HTTPException(status_code=400, detail="prompt ä¸èƒ½ä¸ºç©º")

    resolved_path = _resolve_config_path(payload.config_path)
    session = await _get_or_create_llm_session(
        payload.signature,
        resolved_path,
        system_prompt_override=payload.system_prompt,
    )

    if payload.reset:
        session.reset_history(system_prompt=payload.system_prompt)

    async with session.lock:
        return await _invoke_llm_session(session, prompt)


# =============================================================================
# ä»»åŠ¡ç®¡ç†æ¥å£ (ä¿ç•™åŸæœ‰åŠŸèƒ½)
# =============================================================================
from utils.backup_utils import run_backup_snapshot


@app.post("/api/run-trading")
async def run_trading(config_path: str | None = None):
    """å¯åŠ¨äº¤æ˜“è„šæœ¬"""
    job_id = str(uuid.uuid4())
    started_at = datetime.utcnow().isoformat() + "Z"
    log_file = LOG_DIR / f"{job_id}.log"

    if not _truthy_env("SKIP_API_BACKUP"):
        ok = run_backup_snapshot(reason="api_run_trading")
        if not ok:
            logger.warning("âš ï¸ Pre-run backup failed")

    cmd = [sys.executable, str(Path(__file__).parent / "main.py")]
    if config_path:
        cmd.append(config_path)

    try:
        lf = open(log_file, "wb")
        proc = subprocess.Popen(
            cmd,
            cwd=str(Path(__file__).parent),
            stdout=lf,
            stderr=subprocess.STDOUT,
            bufsize=1,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start process: {e}")

    APP_STATE.jobs[job_id] = {
        "id": job_id,
        "pid": proc.pid,
        "started_at": started_at,
        "status": "running",
        "returncode": None,
        "log_file": str(log_file),
        "process": proc,
    }

    return {"job_id": job_id, "pid": proc.pid, "started_at": started_at}


@app.post("/api/backup")
async def trigger_backup(retain: int = Query(5, ge=1, le=50)):
    ok = run_backup_snapshot(reason="api_manual", retain=retain)
    if not ok:
        raise HTTPException(status_code=500, detail="æ— æ³•å®Œæˆå¤‡ä»½")
    return {"status": "ok", "retain": retain}


@app.get("/api/job/{job_id}")
async def get_job(job_id: str):
    job = APP_STATE.jobs.get(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    proc: subprocess.Popen = job.get("process")
    if proc is not None:
        rc = proc.poll()
        if rc is None:
            status = "running"
        else:
            status = "finished" if rc == 0 else "failed"
            job["returncode"] = rc
            job["status"] = status
            job.pop("process", None)
    else:
        status = job.get("status", "unknown")

    job["status"] = status

    log_text = None
    try:
        lfpath = Path(job["log_file"])
        if lfpath.exists():
            with open(lfpath, "r", encoding="utf-8", errors="ignore") as f:
                f.seek(0, 2)
                size = f.tell()
                start = max(0, size - 2000)
                f.seek(start)
                log_text = f.read()
    except Exception:
        log_text = None

    return {
        "id": job_id,
        "pid": job.get("pid"),
        "status": job.get("status"),
        "started_at": job.get("started_at"),
        "returncode": job.get("returncode"),
        "log_tail": log_text,
    }


@app.get("/api/jobs")
async def list_jobs():
    items = []
    for j in APP_STATE.jobs.values():
        items.append({
            "id": j["id"],
            "pid": j["pid"],
            "status": j["status"],
            "started_at": j["started_at"],
            "log_file": j["log_file"],
        })
    return {"jobs": items}


@app.post("/api/stop/{job_id}")
async def stop_job(job_id: str):
    job = APP_STATE.jobs.get(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")
    proc: subprocess.Popen = job.get("process")
    if not proc:
        raise HTTPException(status_code=400, detail="Process already finished")
    proc.terminate()
    try:
        proc.wait(timeout=5)
    except Exception:
        proc.kill()
    job["status"] = "terminated"
    job.pop("process", None)
    return {"id": job_id, "status": job["status"]}


# =============================================================================
# ä¸»å…¥å£
# =============================================================================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
