"""
News Deduplicator - æ–°é—»å»é‡å·¥å…·
ä½¿ç”¨ all-MiniLM-L6-v2 åµŒå…¥æ¨¡å‹å¯¹æ–°é—»æ ‡é¢˜æˆ–æ‘˜è¦è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—å¹¶å»é‡
"""
import os
import warnings
from typing import List, Dict, Any
import numpy as np

# å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…æ²¡æœ‰å®‰è£… sentence-transformers æ—¶å¯åŠ¨å¤±è´¥
_model = None
_model_name = 'sentence-transformers/all-MiniLM-L6-v2'

def _get_model():
    """å»¶è¿ŸåŠ è½½å¥å­åµŒå…¥æ¨¡å‹"""
    global _model
    if _model is None:
        try:
            from sentence_transformers import SentenceTransformer
            print(f"ğŸ”§ åŠ è½½å¥å­åµŒå…¥æ¨¡å‹: {_model_name}")
            _model = SentenceTransformer(_model_name)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError:
            print("âš ï¸ æœªå®‰è£… sentence-transformersï¼Œè¯·è¿è¡Œ: pip install sentence-transformers")
            raise
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            raise
    return _model


def deduplicate_news_by_embedding(
    news_list: List[Dict[str, Any]],
    similarity_threshold: float = 0.85,
    field_to_compare: str = 'title'
) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨åµŒå…¥å‘é‡ç›¸ä¼¼åº¦å¯¹æ–°é—»è¿›è¡Œå»é‡
    
    Args:
        news_list: æ–°é—»åˆ—è¡¨ï¼Œæ¯æ¡æ–°é—»æ˜¯ä¸€ä¸ªå­—å…¸
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.85ï¼Œè¶…è¿‡æ­¤å€¼çš„è¢«è§†ä¸ºé‡å¤
        field_to_compare: ç”¨äºæ¯”è¾ƒçš„å­—æ®µï¼Œé»˜è®¤'title'ï¼Œä¹Ÿå¯ä»¥æ˜¯'summary'æˆ–'content'
    
    Returns:
        å»é‡åçš„æ–°é—»åˆ—è¡¨
    """
    if not news_list:
        return []
    
    # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
    if not all(field_to_compare in news for news in news_list):
        print(f"âš ï¸ éƒ¨åˆ†æ–°é—»ç¼ºå°‘å­—æ®µ '{field_to_compare}'ï¼Œè·³è¿‡å»é‡")
        return news_list
    
    try:
        model = _get_model()

        # æå–éœ€è¦æ¯”è¾ƒçš„æ–‡æœ¬ï¼ˆä¼˜å…ˆ titleï¼Œå…¶æ¬¡ summaryï¼Œå†æ¬¡ contentï¼‰
        texts: List[str] = []
        for news in news_list:
            val = news.get(field_to_compare)
            if not val:
                # è‡ªåŠ¨å›é€€åˆ° summary / content
                val = news.get('summary') or news.get('content') or ''
            texts.append(str(val).strip())

        # è¿‡æ»¤ç©ºæ–‡æœ¬
        valid_indices = [i for i, text in enumerate(texts) if text]
        if not valid_indices:
            return news_list

        valid_texts = [texts[i] for i in valid_indices]
        valid_news = [news_list[i] for i in valid_indices]

        print(f"ğŸ” å¼€å§‹å¯¹ {len(valid_texts)} æ¡æ–°é—»è¿›è¡ŒåµŒå…¥å»é‡ï¼ˆé˜ˆå€¼={similarity_threshold}ï¼‰")

        # ä¼˜å…ˆä½¿ç”¨ PyTorchï¼Œé¿å… NumPy ä¾èµ–å¯¼è‡´çš„é—®é¢˜ï¼ˆå¦‚ torch<->numpy æ¡¥æ¥å¤±è´¥ï¼‰
        use_torch = False
        try:
            # æŠ‘åˆ¶ torch åˆå§‹åŒ–é˜¶æ®µå¯èƒ½å‡ºç°çš„ä¸ NumPy ç›¸å…³çš„è­¦å‘Š
            warnings.filterwarnings(
                "ignore",
                message=".*Failed to initialize NumPy.*",
                module="torch.*",
            )
            import torch  # type: ignore
            use_torch = True
        except Exception:
            use_torch = False

        if use_torch:
            # ä½¿ç”¨ torch å¼ é‡è®¡ç®—ç›¸ä¼¼åº¦ï¼Œå®Œå…¨ç»•è¿‡ numpy
            embeddings = model.encode(valid_texts, convert_to_numpy=False, show_progress_bar=False)
            import torch  # type: ignore
            if isinstance(embeddings, list):
                embeddings = torch.stack(embeddings)
            elif not isinstance(embeddings, torch.Tensor):
                embeddings = torch.tensor(embeddings)

            embeddings = embeddings.to(dtype=torch.float32)
            embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)
            sim = embeddings @ embeddings.T

            keep_indices = []
            duplicate_count = 0
            for i in range(len(valid_texts)):
                is_duplicate = False
                for j in keep_indices:
                    if sim[i, j].item() >= float(similarity_threshold):
                        is_duplicate = True
                        duplicate_count += 1
                        break
                if not is_duplicate:
                    keep_indices.append(i)
        else:
            # å›é€€åˆ° numpy è·¯å¾„ï¼ˆå¯èƒ½åœ¨éƒ¨åˆ†ç¯å¢ƒä¸‹è§¦å‘ numpy/torch å…¼å®¹é—®é¢˜ï¼‰
            embeddings = model.encode(valid_texts, convert_to_numpy=True, show_progress_bar=False)
            embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
            sim = np.dot(embeddings, embeddings.T)

            keep_indices = []
            duplicate_count = 0
            for i in range(len(valid_texts)):
                is_duplicate = False
                for j in keep_indices:
                    if float(sim[i, j]) >= float(similarity_threshold):
                        is_duplicate = True
                        duplicate_count += 1
                        break
                if not is_duplicate:
                    keep_indices.append(i)

        # æ„å»ºå»é‡åçš„ç»“æœ
        deduplicated = [valid_news[i] for i in keep_indices]

        print(f"âœ… å»é‡å®Œæˆ: åŸå§‹ {len(valid_news)} æ¡ â†’ ä¿ç•™ {len(deduplicated)} æ¡ï¼ˆç§»é™¤ {duplicate_count} æ¡é‡å¤ï¼‰")

        # å°†æœªå‚ä¸æ¯”è¾ƒçš„æ–°é—»ï¼ˆç©ºæ–‡æœ¬ï¼‰ä¹ŸåŠ å›å»
        for i, news in enumerate(news_list):
            if i not in valid_indices:
                deduplicated.append(news)

        return deduplicated

    except Exception as e:
        print(f"âš ï¸ åµŒå…¥å»é‡å¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹åˆ—è¡¨")
        import traceback
        traceback.print_exc()
        return news_list


def deduplicate_news_dataframe(df, similarity_threshold: float = 0.85, field_to_compare: str = 'title'):
    """
    å¯¹ pandas DataFrame æ ¼å¼çš„æ–°é—»æ•°æ®è¿›è¡Œå»é‡
    
    Args:
        df: pandas DataFrameï¼ŒåŒ…å«æ–°é—»æ•°æ®
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.85
        field_to_compare: ç”¨äºæ¯”è¾ƒçš„å­—æ®µï¼Œé»˜è®¤'title'
    
    Returns:
        å»é‡åçš„ DataFrame
    """
    if df is None or df.empty:
        return df
    
    if field_to_compare not in df.columns:
        print(f"âš ï¸ DataFrame ç¼ºå°‘å­—æ®µ '{field_to_compare}'ï¼Œè·³è¿‡å»é‡")
        return df
    
    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    news_list = df.to_dict('records')
    
    # å»é‡
    deduplicated_list = deduplicate_news_by_embedding(
        news_list, 
        similarity_threshold=similarity_threshold,
        field_to_compare=field_to_compare
    )
    
    # è½¬å› DataFrame
    import pandas as pd
    return pd.DataFrame(deduplicated_list)


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    test_news = [
        {"title": "ç§‘åˆ›æ¿å¹³å‡è‚¡ä»·39.44å…ƒï¼Œ8è‚¡è‚¡ä»·è¶…300å…ƒ", "symbol": "SH688008"},
        {"title": "ç§‘åˆ›æ¿å¹³å‡è‚¡ä»·39.44å…ƒ 8è‚¡è‚¡ä»·è¶…300å…ƒ", "symbol": "SH688111"},  # ç›¸ä¼¼åº¦å¾ˆé«˜
        {"title": "æ·±æ²ªåŒ—ç™¾å…ƒè‚¡æ•°é‡è¾¾153åªï¼Œç”µå­è¡Œä¸šå æ¯”æœ€é«˜", "symbol": "SH688008"},
        {"title": "ä¸­èŠ¯å›½é™…ï¼šç»ˆæ­¢å‡ºå”®ä¸­èŠ¯å®æ³¢è‚¡æƒ", "symbol": "SH688981"},
        {"title": "ä¸­èŠ¯å›½é™…ç»ˆæ­¢å‡ºå”®ä¸­èŠ¯å®æ³¢14.832%è‚¡æƒ", "symbol": "SH688981"},  # ç›¸ä¼¼åº¦é«˜
    ]
    
    print("\n" + "="*80)
    print("æµ‹è¯•æ–°é—»å»é‡åŠŸèƒ½")
    print("="*80 + "\n")
    
    result = deduplicate_news_by_embedding(test_news, similarity_threshold=0.85)
    
    print("\nåŸå§‹æ–°é—»:")
    for i, news in enumerate(test_news, 1):
        print(f"{i}. {news['title']}")
    
    print("\nå»é‡å:")
    for i, news in enumerate(result, 1):
        print(f"{i}. {news['title']}")
